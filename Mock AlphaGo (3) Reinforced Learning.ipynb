{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mock AlphaGo (3) - Reinforced Learning\n",
    "In this notebook, we will train the model by letting them compete each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, numpy as np\n",
    "from caffe2.python import core, model_helper, workspace, brew, utils\n",
    "from caffe2.proto import caffe2_pb2\n",
    "\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot\n",
    "\n",
    "# how many games will be run in this tournament\n",
    "# if greater than 1, make sure randomize the choice\n",
    "GAMES_ITERS = 16\n",
    "\n",
    "if workspace.has_gpu_support:\n",
    "    device_opts = core.DeviceOption(caffe2_pb2.CUDA, workspace.GetDefaultGPUID())\n",
    "    print('Running in GPU mode on default device {}'.format(workspace.GetDefaultGPUID()))\n",
    "else :\n",
    "    device_opts = core.DeviceOption(caffe2_pb2.CPU, 0)\n",
    "    print('Running in CPU mode')\n",
    "\n",
    "arg_scope = {\"order\": \"NCHW\"}\n",
    "    \n",
    "ROOT_FOLDER = os.path.join(os.path.expanduser('~'), 'python', 'tutorial_data','go','param') # folder stores the loss/accuracy log\n",
    "DATA_FOLDER = os.path.join(os.path.expanduser('~'), 'python', 'tutorial_data','go')\n",
    "\n",
    "### Config for black player\n",
    "BLACK_WORKSPACE = os.path.join(ROOT_FOLDER,'black')\n",
    "BLACK_CONV_LEVEL = 4\n",
    "BLACK_FILTERS = 128\n",
    "BLACK_PRE_TRAINED_ITERS = 1\n",
    "# before traning, where to load the params\n",
    "BLACK_LOAD_FOLDER = os.path.join(ROOT_FOLDER, \"RL-B-conv={}-k={}-iter={}\".format(BLACK_CONV_LEVEL,BLACK_FILTERS,'na'))\n",
    "BLACK_LOAD_INIT_NET = os.path.join(BLACK_LOAD_FOLDER, \"param_init_net.pb\")\n",
    "BLACK_LOAD_PREDICT_NET = os.path.join(BLACK_LOAD_FOLDER, \"predict_net.pb\")\n",
    "\n",
    "### Config for white player\n",
    "WHITE_WORKSPACE = os.path.join(ROOT_FOLDER,'white')\n",
    "WHITE_CONV_LEVEL = 13\n",
    "WHITE_FILTERS = 192\n",
    "WHITE_PRE_TRAINED_ITERS = 1\n",
    "# before traning, where to load the params\n",
    "WHITE_LOAD_FOLDER = os.path.join(ROOT_FOLDER, \"RL-W-conv={}-k={}-iter={}\".format(WHITE_CONV_LEVEL,WHITE_FILTERS,'na'))\n",
    "WHITE_LOAD_INIT_NET = os.path.join(WHITE_LOAD_FOLDER, \"param_init_net.pb\")\n",
    "WHITE_LOAD_PREDICT_NET = os.path.join(WHITE_LOAD_FOLDER, \"predict_net.pb\")\n",
    "\n",
    "# BOARD_POSITION contains SGF symbol which represents each row (or column) of the board\n",
    "# It can be used to convert between 0,1,2,3... and a,b,c,d...\n",
    "# Symbol [tt] or [] represents PASS in SGF, therefore is omitted\n",
    "BOARD_POSITION = 'abcdefghijklmnopqrs'\n",
    "\n",
    "print('Black {}/{}/{} vs. White {}/{}/{}'.format(\n",
    "    BLACK_CONV_LEVEL, BLACK_FILTERS, BLACK_PRE_TRAINED_ITERS,\n",
    "    WHITE_CONV_LEVEL, WHITE_FILTERS, WHITE_PRE_TRAINED_ITERS))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">training params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "BASE_LR = -0.003 # (-0.01,0) The base Learning Rate, alphago uses -0.003 and half the number every 80m steps\n",
    "\n",
    "TRAIN_BATCHES = 16 # how many samples will be trained within one mini-batch, depends on your hardware\n",
    "#PRE_TRAINED_ITERS = 60000 # [0, infinity) how many batches the model has been trained before\n",
    "#SKIP_TRAINED_DATA = 0 # [0, infinity) if this is a resumed training, how many input data will be skipped\n",
    "#TRAIN_ITERS = 40000 # [0, infinity) how many batches the model will be trained\n",
    "\n",
    "# after training, where to store the params\n",
    "BLACK_SAVE_FOLDER = os.path.join(ROOT_FOLDER, \"RL-B-conv={}-k={}-iter={}\".format(BLACK_CONV_LEVEL,BLACK_FILTERS,'na'))\n",
    "BLACK_SAVE_INIT_NET = os.path.join(BLACK_SAVE_FOLDER, \"param_init_net.pb\")\n",
    "BLACK_SAVE_PREDICT_NET = os.path.join(BLACK_SAVE_FOLDER, \"predict_net.pb\")\n",
    "# after training, where to store the params\n",
    "WHITE_SAVE_FOLDER = os.path.join(ROOT_FOLDER, \"RL-W-conv={}-k={}-iter={}\".format(WHITE_CONV_LEVEL,WHITE_FILTERS,'na'))\n",
    "WHITE_SAVE_INIT_NET = os.path.join(WHITE_SAVE_FOLDER, \"param_init_net.pb\")\n",
    "WHITE_SAVE_PREDICT_NET = os.path.join(WHITE_SAVE_FOLDER, \"predict_net.pb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AlphaGo Neural Network Architecture\n",
    "Refer to AlphaGo\n",
    ">  We also trained a faster but less accurate rollout policy pπ(a|s), using a linear softmax of small pattern features (see Extended Data Table 4) with weights π; this achieved an accuracy of 24.2%, using just 2µs to select an action, rather than 3ms for the policy network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def AddConvModel(model, data, conv_level=13, filters=192):\n",
    "    ''' color is BLACK or WHITE. Black and white players don't share model params.\n",
    "    '''\n",
    "    # Layer 1: 48 x 19 x 19 -pad-> 48 x 23 x 23 -conv-> 192 x 19 x 19\n",
    "    pad1 = model.PadImage(data, 'pad1', pad_t=2, pad_l=2, pad_b=2, pad_r=2, mode=\"constant\", value=0.)\n",
    "    conv1 = brew.conv(model, pad1, 'conv1', dim_in=48, dim_out=filters, kernel=5)\n",
    "    relu1 = brew.relu(model, conv1, 'relu1')\n",
    "    # Layer 2-12: 192 x 19 x 19 -pad-> 192 x 21 x 21 -conv-> 192 x 19 x 19\n",
    "    if conv_level > 2:\n",
    "        pad2 = model.PadImage(relu1, 'pad2', pad_t=1, pad_l=1, pad_b=1, pad_r=1, mode=\"constant\", value=0.)\n",
    "        conv2 = brew.conv(model, pad2, 'conv2', dim_in=filters, dim_out=filters, kernel=3)\n",
    "        relu2 = brew.relu(model, conv2, 'relu2')\n",
    "        relu = relu2\n",
    "    #\n",
    "    if conv_level > 3:\n",
    "        pad3 = model.PadImage(relu2, 'pad3', pad_t=1, pad_l=1, pad_b=1, pad_r=1, mode=\"constant\", value=0.)\n",
    "        conv3 = brew.conv(model, pad3, 'conv3', dim_in=filters, dim_out=filters, kernel=3)\n",
    "        relu3 = brew.relu(model, conv3, 'relu3')\n",
    "        relu = relu3\n",
    "    #\n",
    "    if conv_level > 4:\n",
    "        pad4 = model.PadImage(relu3, 'pad4', pad_t=1, pad_l=1, pad_b=1, pad_r=1, mode=\"constant\", value=0.)\n",
    "        conv4 = brew.conv(model, pad4, 'conv4', dim_in=filters, dim_out=filters, kernel=3)\n",
    "        relu4 = brew.relu(model, conv4, 'relu4')\n",
    "        relu = relu4\n",
    "    #\n",
    "    if conv_level > 5:\n",
    "        pad5 = model.PadImage(relu4, 'pad5', pad_t=1, pad_l=1, pad_b=1, pad_r=1, mode=\"constant\", value=0.)\n",
    "        conv5 = brew.conv(model, pad5, 'conv5', dim_in=filters, dim_out=filters, kernel=3)\n",
    "        relu5 = brew.relu(model, conv5, 'relu5')\n",
    "        relu = relu5\n",
    "    #\n",
    "    if conv_level > 6:\n",
    "        pad6 = model.PadImage(relu5, 'pad6', pad_t=1, pad_l=1, pad_b=1, pad_r=1, mode=\"constant\", value=0.)\n",
    "        conv6 = brew.conv(model, pad6, 'conv6', dim_in=filters, dim_out=filters, kernel=3)\n",
    "        relu6 = brew.relu(model, conv6, 'relu6')\n",
    "        relu = relu6\n",
    "    #\n",
    "    if conv_level > 7:\n",
    "        pad7 = model.PadImage(relu6, 'pad7', pad_t=1, pad_l=1, pad_b=1, pad_r=1, mode=\"constant\", value=0.)\n",
    "        conv7 = brew.conv(model, pad7, 'conv7', dim_in=filters, dim_out=filters, kernel=3)\n",
    "        relu7 = brew.relu(model, conv7, 'relu7')\n",
    "        relu = relu7\n",
    "    #\n",
    "    if conv_level > 8:\n",
    "        pad8 = model.PadImage(relu7, 'pad8', pad_t=1, pad_l=1, pad_b=1, pad_r=1, mode=\"constant\", value=0.)\n",
    "        conv8 = brew.conv(model, pad8, 'conv8', dim_in=filters, dim_out=filters, kernel=3)\n",
    "        relu8 = brew.relu(model, conv8, 'relu8')\n",
    "        relu = relu8\n",
    "    #\n",
    "    if conv_level > 9:\n",
    "        pad9 = model.PadImage(relu8, 'pad9', pad_t=1, pad_l=1, pad_b=1, pad_r=1, mode=\"constant\", value=0.)\n",
    "        conv9 = brew.conv(model, pad9, 'conv9', dim_in=filters, dim_out=filters, kernel=3)\n",
    "        relu9 = brew.relu(model, conv9, 'relu9')\n",
    "        relu = relu9\n",
    "    #\n",
    "    if conv_level > 10:\n",
    "        pad10 = model.PadImage(relu9, 'pad10', pad_t=1, pad_l=1, pad_b=1, pad_r=1, mode=\"constant\", value=0.)\n",
    "        conv10 = brew.conv(model, pad10, 'conv10', dim_in=filters, dim_out=filters, kernel=3)\n",
    "        relu10 = brew.relu(model, conv10, 'relu10')\n",
    "        relu = relu10\n",
    "    #\n",
    "    if conv_level > 11:\n",
    "        pad11 = model.PadImage(relu10, 'pad11', pad_t=1, pad_l=1, pad_b=1, pad_r=1, mode=\"constant\", value=0.)\n",
    "        conv11 = brew.conv(model, pad11, 'conv11', dim_in=filters, dim_out=filters, kernel=3)\n",
    "        relu11 = brew.relu(model, conv11, 'relu11')\n",
    "        relu = relu11\n",
    "    #\n",
    "    if conv_level > 12:\n",
    "        pad12 = model.PadImage(relu11, 'pad12', pad_t=1, pad_l=1, pad_b=1, pad_r=1, mode=\"constant\", value=0.)\n",
    "        conv12 = brew.conv(model, pad12, 'conv12', dim_in=filters, dim_out=filters, kernel=3)\n",
    "        relu12 = brew.relu(model, conv12, 'relu12')\n",
    "        relu = relu12\n",
    "    # Layer 13: 192 x 19 x 19 -conv-> 1 x 19 x 19 -softmax-> 361\n",
    "    conv13 = brew.conv(model, relu, 'conv13', dim_in=filters, dim_out=1, kernel=1)\n",
    "    ## todo: bias layer?\n",
    "    softmax = brew.softmax(model, conv13, 'softmax')\n",
    "    predict = model.Flatten(softmax, 'predict')\n",
    "    return predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Operator (Backward Propagation)\n",
    "The training operator is almost same as MNIST. Refer to AlphaGo\n",
    ">TBD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def AddTrainingOperators(model, softmax, label):\n",
    "    \"\"\"Adds training operators to the model.\"\"\"\n",
    "    xent = model.LabelCrossEntropy([softmax, label], 'xent')\n",
    "    # compute the expected loss\n",
    "    loss = model.AveragedLoss(xent, \"loss\")\n",
    "    # track the accuracy of the model\n",
    "    # AddAccuracy(model, softmax, label)\n",
    "    # use the average loss we just computed to add gradient operators to the model\n",
    "    model.AddGradientOperators([loss])\n",
    "    # do a simple stochastic gradient descent\n",
    "    ITER = brew.iter(model, \"iter\")\n",
    "    # set the learning rate schedule\n",
    "    LR = model.LearningRate(\n",
    "        ITER, \"LR\", base_lr=BASE_LR, policy=\"fixed\", stepsize=1, gamma=0.999 ) # when policy=fixed, stepsize and gamma are ignored\n",
    "    # ONE is a constant value that is used in the gradient update. We only need\n",
    "    # to create it once, so it is explicitly placed in param_init_net.\n",
    "    ONE = model.param_init_net.ConstantFill([], \"ONE\", shape=[1], value=1.0)\n",
    "    # Now, for each parameter, we do the gradient updates.\n",
    "    for param in model.params:\n",
    "        # Note how we get the gradient of each parameter - ModelHelper keeps\n",
    "        # track of that.\n",
    "        param_grad = model.param_to_grad[param]\n",
    "        # The update is a simple weighted sum: param = param + param_grad * LR\n",
    "        model.WeightedSum([param, ONE, param_grad, LR], param)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the actual network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import caffe2.python.predictor.predictor_exporter as pe\n",
    "\n",
    "data = np.empty(shape=(TRAIN_BATCHES,48,19,19), dtype=np.float32)\n",
    "label = np.empty(shape=(TRAIN_BATCHES,1), dtype=np.int32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Net Initialize\n",
    ">Train Net: Blob('data','label') ==> Predict Net ==> Loss ==> Backward Propergation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Black player\n",
    "workspace.SwitchWorkspace(BLACK_WORKSPACE, True)\n",
    "with core.DeviceScope(device_opts):\n",
    "    black_train_model = model_helper.ModelHelper(name=\"black_train_model\", arg_scope=arg_scope, init_params=True)\n",
    "    workspace.FeedBlob(\"data\", data, device_option=device_opts)\n",
    "    workspace.FeedBlob(\"label\", data, device_option=device_opts)\n",
    "    #black_train_model.GivenTensorFill([],\"data\",shape=(TRAIN_BATCHES,48,19,19),values=data)\n",
    "    #black_train_model.GivenTensorFill([],\"label\",shape=(TRAIN_BATCHES,1),values=label)\n",
    "    predict = AddConvModel(black_train_model, \"data\", conv_level=BLACK_CONV_LEVEL, filters=BLACK_FILTERS)\n",
    "    AddTrainingOperators(black_train_model, predict, \"label\")\n",
    "workspace.RunNetOnce(black_train_model.param_init_net)\n",
    "workspace.CreateNet(black_train_model.net, overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize White player\n",
    "workspace.SwitchWorkspace(WHITE_WORKSPACE, True)\n",
    "with core.DeviceScope(device_opts):\n",
    "    white_train_model = model_helper.ModelHelper(name=\"white_train_model\", arg_scope=arg_scope, init_params=True)\n",
    "    workspace.FeedBlob(\"data\", data, device_option=device_opts)\n",
    "    workspace.FeedBlob(\"label\", data, device_option=device_opts)\n",
    "    #white_train_model.GivenTensorFill([],\"data\",shape=(TRAIN_BATCHES,48,19,19),values=data)\n",
    "    #white_train_model.GivenTensorFill([],\"label\",shape=(TRAIN_BATCHES,1),values=label)\n",
    "    predict = AddConvModel(white_train_model, \"data\", conv_level=WHITE_CONV_LEVEL, filters=WHITE_FILTERS)\n",
    "    AddTrainingOperators(white_train_model, predict, \"label\")\n",
    "workspace.RunNetOnce(white_train_model.param_init_net)\n",
    "workspace.CreateNet(white_train_model.net, overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deploy Net\n",
    "Build Deploy Net and Init Deploy Net with saved weight and bias.\n",
    ">Predict Net: Blob('data') ==> Predict Net ==> Blob('predict')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Black player\n",
    "workspace.SwitchWorkspace(BLACK_WORKSPACE, True)\n",
    "with core.DeviceScope(device_opts):\n",
    "    black_deploy_model = model_helper.ModelHelper(name=\"black_policy_deploy\", arg_scope=arg_scope, init_params=False)\n",
    "    AddConvModel(black_deploy_model, \"data\", conv_level=BLACK_CONV_LEVEL, filters=BLACK_FILTERS)\n",
    "if BLACK_PRE_TRAINED_ITERS > 0:\n",
    "    black_deploy_model.net = pe.prepare_prediction_net(os.path.join(BLACK_LOAD_FOLDER, \"policy_model.minidb\"), \"minidb\", device_option=device_opts)\n",
    "else:\n",
    "    workspace.RunNetOnce(black_deploy_model.param_init_net)\n",
    "workspace.CreateNet(black_deploy_model.net, overwrite=True)\n",
    "\n",
    "# Initialize White player\n",
    "workspace.SwitchWorkspace(WHITE_WORKSPACE, True)\n",
    "with core.DeviceScope(device_opts):\n",
    "    white_deploy_model = model_helper.ModelHelper(name=\"white_policy_deploy\", arg_scope=arg_scope, init_params=False)\n",
    "    AddConvModel(white_deploy_model, \"data\", conv_level=WHITE_CONV_LEVEL, filters=WHITE_FILTERS)\n",
    "if WHITE_PRE_TRAINED_ITERS > 0:\n",
    "    white_deploy_model.net = pe.prepare_prediction_net(os.path.join(WHITE_LOAD_FOLDER, \"policy_model.minidb\"), \"minidb\", device_option=device_opts)\n",
    "else:\n",
    "    workspace.RunNetOnce(white_deploy_model.param_init_net)\n",
    "workspace.CreateNet(white_deploy_model.net, overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the tournament and training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from go import GameState, BLACK, WHITE, EMPTY\n",
    "from preprocessing import Preprocess\n",
    "from datetime import datetime\n",
    "\n",
    "game_state = [GameState() for i in range(GAMES_ITERS)]\n",
    "game_result = [0] * GAMES_ITERS # 0 - Not Ended; BLACK - Black Wins; WHITE - White Wins\n",
    "p = [Preprocess()] * GAMES_ITERS\n",
    "history = [[] for i in range(GAMES_ITERS)]\n",
    "# board before current move\n",
    "board = [p[i].state_to_tensor(game_state[i]).astype(np.float32) for i in range(GAMES_ITERS)]\n",
    "\n",
    "# diverse the first step for GAMES_ITERS choices\n",
    "workspace.SwitchWorkspace(BLACK_WORKSPACE)\n",
    "workspace.FeedBlob('data', board[0], device_option=device_opts)\n",
    "\n",
    "workspace.RunNet(black_deploy_model.net)\n",
    "init_move = np.reshape(workspace.FetchBlob('predict'), (-1))\n",
    "init_sorted_move = np.argsort(-init_move) # shape=(361,)\n",
    "\n",
    "current_choice = init_sorted_move[0:GAMES_ITERS]\n",
    "x = current_choice/19 # tensor\n",
    "y = current_choice%19 # tensor\n",
    "\n",
    "for i in range(GAMES_ITERS):\n",
    "    history[i].append(('B',x[i],y[i],board[i]))\n",
    "    game_state[i].do_move(action=(x[i],y[i]),color = BLACK)\n",
    "    print('game({}) step({}) black move({},{})'.format(i, 0, x[i], y[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for each step in the game\n",
    "for step in range(1,500):\n",
    "\n",
    "#    for i in range(GAMES_ITERS):\n",
    "#        if not game_result[i]:\n",
    "#            board[i] = np.append(board[i], p[i].state_to_tensor(game_state[i]).astype(np.float32), axis=0)\n",
    "    board = np.concatenate([p[i].state_to_tensor(game_state[i]).astype(np.float32) for i in range(GAMES_ITERS)])\n",
    "\n",
    "    # pass move = if all moves are illegal\n",
    "    pass_move = [True] * GAMES_ITERS\n",
    "    \n",
    "    if step % 2 == 0:\n",
    "        # black move\n",
    "        workspace.SwitchWorkspace(BLACK_WORKSPACE)\n",
    "        workspace.FeedBlob('data', board, device_option=device_opts)\n",
    "        workspace.RunNet(black_deploy_model.net)\n",
    "        move = np.reshape(workspace.FetchBlob('predict'), (GAMES_ITERS,-1))\n",
    "        sorted_move = np.argsort(-move)\n",
    "        for i in range(GAMES_ITERS):\n",
    "            if game_result[i]:\n",
    "                break;\n",
    "            for current_choice in sorted_move[i]:\n",
    "                x = current_choice/19\n",
    "                y = current_choice%19\n",
    "                if game_state[i].is_legal(action=(x,y)) and not game_state[i].is_eye((x, y), BLACK):\n",
    "                    pass_move[i] = False\n",
    "                    history[i].append(('B',x,y,board[i]))\n",
    "                    game_result[i] = game_state[i].do_move(action=(x,y),color = BLACK) # End of Game?\n",
    "                    print('game({}) step({}) black move({},{})'.format(i, step, x, y))\n",
    "                    break\n",
    "    else:\n",
    "        # white move\n",
    "        workspace.SwitchWorkspace(WHITE_WORKSPACE)\n",
    "        workspace.FeedBlob('data', board, device_option=device_opts)\n",
    "        workspace.RunNet(white_deploy_model.net)\n",
    "        move = np.reshape(workspace.FetchBlob('predict'), (GAMES_ITERS,-1))\n",
    "        sorted_move = np.argsort(-move)\n",
    "        for i in range(GAMES_ITERS):\n",
    "            if game_result[i]:\n",
    "                break;\n",
    "            for current_choice in sorted_move[i]:\n",
    "                x = current_choice/19\n",
    "                y = current_choice%19\n",
    "                if game_state[i].is_legal(action=(x,y)) and not game_state[i].is_eye((x, y), WHITE):\n",
    "                    pass_move[i] = False\n",
    "                    history[i].append(('W',x,y,board[i]))\n",
    "                    game_result[i] = game_state[i].do_move(action=(x,y),color = WHITE) # End of Game?\n",
    "                    print('game({}) step({}) white move({},{})'.format(i, step, x, y))\n",
    "                    break\n",
    "                    \n",
    "    game_result = [game_result[i] or pass_move[i] for i in range(GAMES_ITERS)]\n",
    "    \n",
    "    if np.all(game_result):\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Record the game in SGF format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sgf\n",
    "def write_back_sgf(game_state, history, i):\n",
    "    parser = sgf.Parser()\n",
    "    collection = sgf.Collection(parser)\n",
    "    parser.start_gametree()\n",
    "    parser.start_node()\n",
    "    parser.start_property('FF') # SGF format version\n",
    "    parser.add_prop_value('4')\n",
    "    parser.end_property()\n",
    "    parser.start_property('SZ') # Board Size = 19\n",
    "    parser.add_prop_value('19')\n",
    "    parser.end_property()\n",
    "    parser.start_property('KM') # Komi = 7.5\n",
    "    parser.add_prop_value('7.5')\n",
    "    parser.end_property()\n",
    "    parser.start_property('PB') # Black Player = Supervised Learning / Reinforced Learning\n",
    "    parser.add_prop_value('RL-{}')\n",
    "    parser.end_property()\n",
    "    parser.start_property('PW') # White Player = Supervised Learning / Reinforced Learning\n",
    "    parser.add_prop_value('SL-{}')\n",
    "    parser.end_property()\n",
    "    parser.start_property('DT') # Game Date\n",
    "    parser.add_prop_value(datetime.now().strftime(\"%Y-%m-%d\"))\n",
    "    parser.end_property()\n",
    "    parser.start_property('RE') # Result = B+, W+, T\n",
    "    winner = game_state.get_winner()\n",
    "    if winner == BLACK:\n",
    "        parser.add_prop_value('B+')\n",
    "        winner = 'B+'\n",
    "    elif winner == WHITE:\n",
    "        parser.add_prop_value('W+')\n",
    "        winner = 'W+'\n",
    "    else:\n",
    "        parser.add_prop_value('T')\n",
    "        winner = 'T'\n",
    "    parser.end_property()\n",
    "    parser.end_node()\n",
    "    \n",
    "    for step in history:\n",
    "        parser.start_node()\n",
    "        parser.start_property(step[0]) # or W\n",
    "        parser.add_prop_value(BOARD_POSITION[step[1]]+BOARD_POSITION[step[2]])\n",
    "        parser.end_property()\n",
    "        parser.end_node()\n",
    "    \n",
    "    parser.end_gametree()\n",
    "    \n",
    "    # record the game in SGF\n",
    "    with open(os.path.join(os.path.expanduser('~'), 'python', 'tutorial_files','selfplay',\n",
    "                           '({}_{}_{})vs({}_{}_{})_{}_{}_{}.sgf'.format(\n",
    "                               BLACK_CONV_LEVEL, BLACK_FILTERS, BLACK_PRE_TRAINED_ITERS,\n",
    "                               WHITE_CONV_LEVEL, WHITE_FILTERS, WHITE_PRE_TRAINED_ITERS,\n",
    "                               winner,\n",
    "                               i,\n",
    "                               datetime.now().strftime(\"%Y-%m-%d\"))), \"w\") as f:\n",
    "        collection.output(f)\n",
    "\n",
    "#comment out for better performance\n",
    "for i in range(GAMES_ITERS):\n",
    "    write_back_sgf(game_state[i], history[i], i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learn from the winning games"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iter = 0\n",
    "k = 0\n",
    "for i in range(GAMES_ITERS):\n",
    "    winner = game_state[i].get_winner()\n",
    "    print('Learning {} steps in {} of {} games. {} wins'.format(iter * 32, i, GAMES_ITERS, history[i][0][0]))\n",
    "    for step in history[i]:\n",
    "        if (step[0] == 'B' and winner == BLACK) or (step[0] == 'W' and winner == WHITE):\n",
    "            data[k] = step[3]\n",
    "            label[k] = step[1]*19+step[2]\n",
    "            k += 1\n",
    "            if k == TRAIN_BATCHES:\n",
    "                iter += 1\n",
    "                k = 0\n",
    "                workspace.SwitchWorkspace(BLACK_WORKSPACE)\n",
    "                workspace.FeedBlob(\"data\", data, device_option=device_opts)\n",
    "                workspace.FeedBlob(\"label\", label, device_option=device_opts)\n",
    "                workspace.RunNet(black_train_model.net)\n",
    "                workspace.SwitchWorkspace(WHITE_WORKSPACE)\n",
    "                workspace.FeedBlob(\"data\", data, device_option=device_opts)\n",
    "                workspace.FeedBlob(\"label\", label, device_option=device_opts)\n",
    "                workspace.RunNet(white_train_model.net)\n",
    "print('Finished')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the RL model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(BLACK_SAVE_FOLDER):\n",
    "    os.makedirs(BLACK_SAVE_FOLDER)\n",
    "# construct the model to be exported\n",
    "pe_meta = pe.PredictorExportMeta(\n",
    "    predict_net=black_deploy_model.net.Proto(),\n",
    "    parameters=[str(b) for b in black_deploy_model.params], \n",
    "    inputs=[\"data\"],\n",
    "    outputs=[\"predict\"],\n",
    ")\n",
    "pe.save_to_db(\"minidb\", os.path.join(BLACK_SAVE_FOLDER, \"policy_model.minidb\"), pe_meta)\n",
    "print('Params saved to {}'.format(BLACK_SAVE_FOLDER))\n",
    "    \n",
    "if not os.path.exists(WHITE_SAVE_FOLDER):\n",
    "    os.makedirs(WHITE_SAVE_FOLDER)\n",
    "# construct the model to be exported\n",
    "pe_meta = pe.PredictorExportMeta(\n",
    "    predict_net=white_deploy_model.net.Proto(),\n",
    "    parameters=[str(b) for b in white_deploy_model.params], \n",
    "    inputs=[\"data\"],\n",
    "    outputs=[\"predict\"],\n",
    ")\n",
    "pe.save_to_db(\"minidb\", os.path.join(WHITE_SAVE_FOLDER, \"policy_model.minidb\"), pe_meta)\n",
    "print('Params saved to {}'.format(WHITE_SAVE_FOLDER))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "315px",
    "width": "367px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": false,
   "threshold": 4,
   "toc_cell": false,
   "toc_position": {
    "height": "437px",
    "left": "2px",
    "right": "1723px",
    "top": "107px",
    "width": "130px"
   },
   "toc_section_display": "block",
   "toc_window_display": true,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
