{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mock AlphaGo Zero (2) - Policy and Value Network\n",
    "In this notebook, we will build the model of AlphaGo's Policy Network, which is a dCNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running in GPU mode on default device 0\n",
      "Training model from 0 to 1000 iterations\n"
     ]
    }
   ],
   "source": [
    "import os, numpy as np\n",
    "from caffe2.python import core, model_helper, workspace, brew, utils\n",
    "from caffe2.proto import caffe2_pb2\n",
    "\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot\n",
    "\n",
    "NUM_RES_BLOCKS = 4 # [19(alphago zero),39] How many Residual Blocks will be used in the model\n",
    "FILTERS = 256 # 128/192/256(alphago zero)/384 How many K will be used in the model\n",
    "BASE_LR = -0.1 # (-0.1,0) The base Learning Rate, alphago zero uses -0.1 and times 0.1 every 200K iters\n",
    "\n",
    "if workspace.has_gpu_support:\n",
    "    device_opts = core.DeviceOption(caffe2_pb2.CUDA, workspace.GetDefaultGPUID())\n",
    "    print('Running in GPU mode on default device {}'.format(workspace.GetDefaultGPUID()))\n",
    "else :\n",
    "    device_opts = core.DeviceOption(caffe2_pb2.CPU, 0)\n",
    "    print('Running in CPU mode')\n",
    "\n",
    "TRAIN_BATCHES = 100 # how many samples will be trained within one mini-batch, depends on your hardware\n",
    "PRE_TRAINED_ITERS = 0 # [0, infinity) how many batches the model has been trained before\n",
    "SKIP_TRAINED_DATA = 0 # [0, infinity) if this is a resumed training, how many input data will be skipped\n",
    "TRAIN_ITERS = 1000 # [0, infinity) how many batches the model will be trained\n",
    "TEST_BATCHES = 100 # how many samples will be tested within one mini-batch\n",
    "TEST_ITERS = 100 # how many batches the model will be tested\n",
    "\n",
    "ROOT_FOLDER = os.path.join(os.path.expanduser('~'), 'python', 'tutorial_data','zero','param') # folder stores the loss/accuracy log\n",
    "DATA_FOLDER = os.path.join(os.path.expanduser('~'), 'python', 'tutorial_data','zero')\n",
    "TRAIN_DATA = os.path.join(DATA_FOLDER,'tr_data') # db folder stores the preprocessed games\n",
    "TEST_DATA = os.path.join(DATA_FOLDER,'test_data') # db folder stores the preprocessed games\n",
    "\n",
    "# if this is a resumed training, where to load the init_param from\n",
    "LOAD_FOLDER = os.path.join(ROOT_FOLDER, \"res={}-k={}-iter={}\".format(NUM_RES_BLOCKS,FILTERS,PRE_TRAINED_ITERS))\n",
    "\n",
    "# if the model will be saved for future resume training, where to store it\n",
    "SAVE_FOLDER = os.path.join(ROOT_FOLDER, \"res={}-k={}-iter={}\".format(NUM_RES_BLOCKS,FILTERS,PRE_TRAINED_ITERS+TRAIN_ITERS))\n",
    "\n",
    "workspace.ResetWorkspace(ROOT_FOLDER)\n",
    "\n",
    "print('Training model from {} to {} iterations'.format(PRE_TRAINED_ITERS,PRE_TRAINED_ITERS+TRAIN_ITERS))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AlphaGo Neural Network Architecture\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Input\n",
    ">The input to the neural network is a 19 × 19 × 17 image stack\n",
    "comprising 17 binary feature planes. 8 feature planes $X_t$ consist of binary values indicating the\n",
    "presence of the current player’s stones ($X_t^i = 1$ if intersection $i$ contains a stone of the player’s\n",
    "colour at time-step $t$; $0$ if the intersection is empty, contains an opponent stone, or if $t < 0$). A\n",
    "further 8 feature planes, $Y_t$ , represent the corresponding features for the opponent’s stones. The\n",
    "final feature plane, $C$, represents the colour to play, and has a constant value of either 1 if black\n",
    "is to play or 0 if white is to play. These planes are concatenated together to give input features\n",
    "$s_t = [X_t , Y_t , X_{t−1} , Y_{t−1} , ..., X_{t−7} , Y_{t−7} , C]$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from modelingZero import AddInput"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DCNN\n",
    ">The input features $S_t$ are processed by a residual tower that consists of a single convolutional block followed by either 19 or 39 residual blocks 4. The convolutional block applies the following modules:\n",
    "1. A convolution of 256 filters of kernel size 3 x 3 with stride 1\n",
    "2. Batch normalisation 18\n",
    "3. A rectifier non-linearity\n",
    "\n",
    ">Each residual block applies the following modules sequentially to its input:\n",
    "1. A convolution of 256 filters of kernel size 3 x 3 with stride 1\n",
    "2. Batch normalisation\n",
    "3. A rectifier non-linearity\n",
    "4. A convolution of 256 filters of kernel size 3 x 3 with stride 1\n",
    "5. Batch normalisation\n",
    "6. A skip connection that adds the input to the block\n",
    "7. A rectifier non-linearity\n",
    "\n",
    ">The output of the residual tower is passed into two separate “heads” for computing the policy and value respectively. The policy head applies the following modules:\n",
    "1. A convolution of 2 filters of kernel size 1 x 1 with stride 1\n",
    "2. Batch normalisation\n",
    "3. A rectifier non-linearity\n",
    "4. A fully connected linear layer that outputs a vector of size 192 + 1 = 362 corresponding to logit probabilities for all intersections and the pass move\n",
    "\n",
    ">The value head applies the following modules:\n",
    "1. A convolution of 1 filter of kernel size 1 x 1 with stride 1\n",
    "2. Batch normalisation\n",
    "3. A rectifier non-linearity\n",
    "4. A fully connected linear layer to a hidden layer of size 256\n",
    "5. A rectifier non-linearity\n",
    "6. A fully connected linear layer to a scalar\n",
    "7. A tanh non-linearity outputting a scalar in the range `[-1; 1]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from modelingZero import AddResNetModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy\n",
    "Please note predict is 4 dimensional tensor in shape of N x 1 x 19 x 19, and label is 2 dimensional tensor in shape of N x 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from modelingZero import AddAccuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Operator (Backward Propagation)\n",
    "\n",
    ">A game terminates at step $T$ when both players pass, when the search value drops below a \n",
    "resignation threshold (`10%`), or when the game exceeds a maximum length (`722 steps`); \n",
    "the game is then scored to give a final reward of $r_T\\in\\{-1,+1\\}$ (see\n",
    "Methods for details). The data for each time-step $t$ is stored as $(s_t, \\pi_t, z_t)$ \n",
    "where $z_t = \\pm r_T$ is the game winner from the perspective of the current player at step $t$.\n",
    "In parallel (Figure 1b), new network parameters $\\theta_i$ are trained from data $(s,\\pi,z)$\n",
    "sampled uniformly among all time-steps of the last iteration(s) of self-play. The neural \n",
    "network $(p,v) = f_{\\theta _i}(s)$ is adjusted to minimise the error between the predicted \n",
    "value $v$ and the self-play winner $z$, and to maximise the similarity of the neural network \n",
    "move probabilities $p$ to the search probabilities $\\pi$. Specifically, the parameters $\\theta$\n",
    "are adjusted by gradient descent on a loss function $l$ that sums over mean-squared error and\n",
    "cross-entropy losses respectively,\n",
    "\n",
    ">>$(p,v) = f_\\theta(s), l = (z - v)^2 \\pi^T \\log p + c|| \\theta ||^2$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from modelingZero import AddTrainingOperators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trace the training progress\n",
    "Print 'accuracy' and 'loss' to file and we can monitor them elsewhere."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from modelingZero import AddBookkeepingOperators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the actual network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "arg_scope = {\"order\": \"NCHW\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Skip model only has DBInput to waste the input\n",
    "skip_model = model_helper.ModelHelper(name=\"skip_model\", arg_scope=arg_scope, init_params=True)\n",
    "_d, _l, _r = AddInput(\n",
    "    skip_model, batch_size=TRAIN_BATCHES,\n",
    "    db=TRAIN_DATA,\n",
    "    db_type='leveldb')\n",
    "# Initialize params and create network\n",
    "workspace.RunNetOnce(skip_model.param_init_net)\n",
    "workspace.CreateNet(skip_model.net, overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:You are creating an op that the ModelHelper does not recognize: PadImage.\n",
      "WARNING:root:You are creating an op that the ModelHelper does not recognize: Normalize.\n",
      "WARNING:root:You are creating an op that the ModelHelper does not recognize: PadImage.\n",
      "WARNING:root:You are creating an op that the ModelHelper does not recognize: Normalize.\n",
      "WARNING:root:You are creating an op that the ModelHelper does not recognize: PadImage.\n",
      "WARNING:root:You are creating an op that the ModelHelper does not recognize: Normalize.\n",
      "WARNING:root:You are creating an op that the ModelHelper does not recognize: PadImage.\n",
      "WARNING:root:You are creating an op that the ModelHelper does not recognize: Normalize.\n",
      "WARNING:root:You are creating an op that the ModelHelper does not recognize: PadImage.\n",
      "WARNING:root:You are creating an op that the ModelHelper does not recognize: Normalize.\n",
      "WARNING:root:You are creating an op that the ModelHelper does not recognize: PadImage.\n",
      "WARNING:root:You are creating an op that the ModelHelper does not recognize: Normalize.\n",
      "WARNING:root:You are creating an op that the ModelHelper does not recognize: PadImage.\n",
      "WARNING:root:You are creating an op that the ModelHelper does not recognize: Normalize.\n",
      "WARNING:root:You are creating an op that the ModelHelper does not recognize: PadImage.\n",
      "WARNING:root:You are creating an op that the ModelHelper does not recognize: Normalize.\n",
      "WARNING:root:You are creating an op that the ModelHelper does not recognize: PadImage.\n",
      "WARNING:root:You are creating an op that the ModelHelper does not recognize: Normalize.\n",
      "WARNING:root:You are creating an op that the ModelHelper does not recognize: Normalize.\n",
      "WARNING:root:You are creating an op that the ModelHelper does not recognize: Normalize.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train Net: DBInput ==> Predict Net ==> Loss ==> Backward Propergation\n",
    "with core.DeviceScope(device_opts):\n",
    "    train_model = model_helper.ModelHelper(name=\"policy_train\", arg_scope=arg_scope, init_params=True)\n",
    "    data, label, reward = AddInput(\n",
    "        train_model, batch_size=TRAIN_BATCHES,\n",
    "        db=TRAIN_DATA,\n",
    "        db_type='leveldb')\n",
    "    predict, value = AddResNetModel(train_model, data, num_blocks=NUM_RES_BLOCKS, filters=FILTERS, dim_in=17)\n",
    "    AddTrainingOperators(train_model, predict, label, value, reward, base_lr=BASE_LR)\n",
    "    AddBookkeepingOperators(train_model)\n",
    "# Initialize params and create network\n",
    "workspace.RunNetOnce(train_model.param_init_net)\n",
    "workspace.CreateNet(train_model.net, overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:You are creating an op that the ModelHelper does not recognize: PadImage.\n",
      "WARNING:root:You are creating an op that the ModelHelper does not recognize: Normalize.\n",
      "WARNING:root:You are creating an op that the ModelHelper does not recognize: PadImage.\n",
      "WARNING:root:You are creating an op that the ModelHelper does not recognize: Normalize.\n",
      "WARNING:root:You are creating an op that the ModelHelper does not recognize: PadImage.\n",
      "WARNING:root:You are creating an op that the ModelHelper does not recognize: Normalize.\n",
      "WARNING:root:You are creating an op that the ModelHelper does not recognize: PadImage.\n",
      "WARNING:root:You are creating an op that the ModelHelper does not recognize: Normalize.\n",
      "WARNING:root:You are creating an op that the ModelHelper does not recognize: PadImage.\n",
      "WARNING:root:You are creating an op that the ModelHelper does not recognize: Normalize.\n",
      "WARNING:root:You are creating an op that the ModelHelper does not recognize: PadImage.\n",
      "WARNING:root:You are creating an op that the ModelHelper does not recognize: Normalize.\n",
      "WARNING:root:You are creating an op that the ModelHelper does not recognize: PadImage.\n",
      "WARNING:root:You are creating an op that the ModelHelper does not recognize: Normalize.\n",
      "WARNING:root:You are creating an op that the ModelHelper does not recognize: PadImage.\n",
      "WARNING:root:You are creating an op that the ModelHelper does not recognize: Normalize.\n",
      "WARNING:root:You are creating an op that the ModelHelper does not recognize: PadImage.\n",
      "WARNING:root:You are creating an op that the ModelHelper does not recognize: Normalize.\n",
      "WARNING:root:You are creating an op that the ModelHelper does not recognize: Normalize.\n",
      "WARNING:root:You are creating an op that the ModelHelper does not recognize: Normalize.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test Net: DBInput ==> Predict Net ==> Accuracy\n",
    "with core.DeviceScope(device_opts):\n",
    "    test_model = model_helper.ModelHelper(name=\"policy_test\", arg_scope=arg_scope, init_params=False)\n",
    "    data, label, reward = AddInput(\n",
    "        test_model, batch_size=TEST_BATCHES,\n",
    "        db=TEST_DATA,\n",
    "        db_type='leveldb')\n",
    "    predict, value = AddResNetModel(test_model, data, num_blocks=NUM_RES_BLOCKS, filters=FILTERS, dim_in=17)\n",
    "    AddAccuracy(test_model, predict, label)\n",
    "# Initialize params and create network\n",
    "workspace.RunNetOnce(test_model.param_init_net)\n",
    "workspace.CreateNet(test_model.net, overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deploy Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:You are creating an op that the ModelHelper does not recognize: PadImage.\n",
      "WARNING:root:You are creating an op that the ModelHelper does not recognize: Normalize.\n",
      "WARNING:root:You are creating an op that the ModelHelper does not recognize: PadImage.\n",
      "WARNING:root:You are creating an op that the ModelHelper does not recognize: Normalize.\n",
      "WARNING:root:You are creating an op that the ModelHelper does not recognize: PadImage.\n",
      "WARNING:root:You are creating an op that the ModelHelper does not recognize: Normalize.\n",
      "WARNING:root:You are creating an op that the ModelHelper does not recognize: PadImage.\n",
      "WARNING:root:You are creating an op that the ModelHelper does not recognize: Normalize.\n",
      "WARNING:root:You are creating an op that the ModelHelper does not recognize: PadImage.\n",
      "WARNING:root:You are creating an op that the ModelHelper does not recognize: Normalize.\n",
      "WARNING:root:You are creating an op that the ModelHelper does not recognize: PadImage.\n",
      "WARNING:root:You are creating an op that the ModelHelper does not recognize: Normalize.\n",
      "WARNING:root:You are creating an op that the ModelHelper does not recognize: PadImage.\n",
      "WARNING:root:You are creating an op that the ModelHelper does not recognize: Normalize.\n",
      "WARNING:root:You are creating an op that the ModelHelper does not recognize: PadImage.\n",
      "WARNING:root:You are creating an op that the ModelHelper does not recognize: Normalize.\n",
      "WARNING:root:You are creating an op that the ModelHelper does not recognize: PadImage.\n",
      "WARNING:root:You are creating an op that the ModelHelper does not recognize: Normalize.\n",
      "WARNING:root:You are creating an op that the ModelHelper does not recognize: Normalize.\n",
      "WARNING:root:You are creating an op that the ModelHelper does not recognize: Normalize.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train Net: Blob('data') ==> Predict Net ==> Blob('predict')\n",
    "with core.DeviceScope(device_opts):\n",
    "    deploy_model = model_helper.ModelHelper(name=\"policy_deploy\", arg_scope=arg_scope, init_params=False)\n",
    "    AddResNetModel(deploy_model, 'data', num_blocks=NUM_RES_BLOCKS, filters=FILTERS, dim_in=17)\n",
    "# Initialize params and create network\n",
    "workspace.RunNetOnce(deploy_model.param_init_net)\n",
    "workspace.CreateNet(deploy_model.net, overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the training and testing\n",
    "### resume from last training\n",
    "    Training a multi-level CNN takes quite a long time. To pause-and-resume the training, set the PRE_TRAINED_ITERS so the program will start from where last time it was."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import caffe2.python.predictor.predictor_exporter as pe\n",
    "\n",
    "# construct the model to be exported\n",
    "pe_meta = pe.PredictorExportMeta(\n",
    "    predict_net=deploy_model.net.Proto(),\n",
    "    parameters=[str(b) for b in deploy_model.params], \n",
    "    inputs=[\"data\"],\n",
    "    outputs=[\"predict\"],\n",
    ")\n",
    "\n",
    "if PRE_TRAINED_ITERS > 0:\n",
    "    #load_net(LOAD_INIT_NET, LOAD_PREDICT_NET)\n",
    "    # load the predict net\n",
    "    with core.DeviceScope(device_opts):\n",
    "        deploy_model.net = pe.prepare_prediction_net(os.path.join(LOAD_FOLDER, \"policy_model.minidb\"), \"minidb\")\n",
    "    print('Params loaded from {}'.format(LOAD_FOLDER))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#%%capture output # Jupyter magic command to capture the output\n",
    "\n",
    "if TRAIN_ITERS > 0:\n",
    "    # skip the data which should not be trained again\n",
    "    for i in range(SKIP_TRAINED_DATA):\n",
    "        workspace.RunNet(skip_model.net)\n",
    "    \n",
    "    # set the number of iterations and track the accuracy & loss\n",
    "    accuracy = np.zeros(TRAIN_ITERS)\n",
    "    loss = np.zeros(TRAIN_ITERS)\n",
    "    loss1 = np.zeros(TRAIN_ITERS)\n",
    "    loss2 = np.zeros(TRAIN_ITERS)\n",
    "    # Now, run the network \n",
    "    for i in range(TRAIN_ITERS):\n",
    "        workspace.RunNet(train_model.net)\n",
    "        accuracy[i] = workspace.FetchBlob('accuracy')\n",
    "        loss[i] = workspace.FetchBlob('loss')\n",
    "        loss1[i] = workspace.FetchBlob('loss1')\n",
    "        loss2[i] = workspace.FetchBlob('loss2')\n",
    "        # checkpoint every 10000 iterations\n",
    "        if i > 0 and i % 10000 == 0:\n",
    "            if not os.path.exists(SAVE_FOLDER):\n",
    "                os.makedirs(SAVE_FOLDER)\n",
    "            pe.save_to_db(\"minidb\", os.path.join(SAVE_FOLDER, \"policy_model_checkpoint_{}.minidb\".format(PRE_TRAINED_ITERS+i)), pe_meta)\n",
    "            print('Checkpoint {} saved to {}'.format(PRE_TRAINED_ITERS+i,SAVE_FOLDER))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After the execution is done, plot the values.\n",
    "pyplot.plot(loss1, 'b')\n",
    "pyplot.plot(loss2, 'g')\n",
    "pyplot.plot(accuracy, 'r')\n",
    "pyplot.plot(loss, 'pink')\n",
    "pyplot.legend(('Loss', 'Accuracy'), loc='upper right')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_accuracy = np.zeros(TEST_ITERS)\n",
    "for i in range(TEST_ITERS):\n",
    "    workspace.RunNet(test_model.net)\n",
    "    test_accuracy[i] = workspace.FetchBlob('accuracy')\n",
    "# After the execution is done, let's plot the values.\n",
    "pyplot.plot(test_accuracy, 'r')\n",
    "pyplot.title('Acuracy over test batches.')\n",
    "print('test_accuracy: %f' % test_accuracy.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the work for future use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if TRAIN_ITERS > 0:\n",
    "    if not os.path.exists(SAVE_FOLDER):\n",
    "        os.makedirs(SAVE_FOLDER)\n",
    "    # save the model to a file. Use minidb as the file format\n",
    "    pe.save_to_db(\"minidb\", os.path.join(SAVE_FOLDER, \"policy_model.minidb\"), pe_meta)\n",
    "    print('Params saved to {}'.format(SAVE_FOLDER))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "workspace.FetchBlob('loss1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "workspace.FetchBlob('loss2').shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "workspace.FetchBlob('policy').shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "30px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_position": {
    "height": "856px",
    "left": "0px",
    "right": "20px",
    "top": "107px",
    "width": "179px"
   },
   "toc_section_display": "block",
   "toc_window_display": true,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
