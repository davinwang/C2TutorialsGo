{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mock AlphaGo Zero (2) - Policy and Value Network\n",
    "In this notebook, we will build the model of AlphaGo's Policy Network, which is a dCNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running in GPU mode on default device 0\n",
      "Training model from 0 to 1000 iterations\n"
     ]
    }
   ],
   "source": [
    "import os, numpy as np\n",
    "from caffe2.python import core, model_helper, workspace, brew, utils\n",
    "from caffe2.proto import caffe2_pb2\n",
    "\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot\n",
    "\n",
    "NUM_RES_BLOCKS = 4 # [19(alphago zero),39] How many Residual Blocks will be used in the model\n",
    "FILTERS = 256 # 128/192/256(alphago zero)/384 How many K will be used in the model\n",
    "BASE_LR = -0.1 # (-0.1,0) The base Learning Rate, alphago zero uses -0.1 and times 0.1 every 200K iters\n",
    "\n",
    "if workspace.has_gpu_support:\n",
    "    device_opts = core.DeviceOption(caffe2_pb2.CUDA, workspace.GetDefaultGPUID())\n",
    "    print('Running in GPU mode on default device {}'.format(workspace.GetDefaultGPUID()))\n",
    "else :\n",
    "    device_opts = core.DeviceOption(caffe2_pb2.CPU, 0)\n",
    "    print('Running in CPU mode')\n",
    "\n",
    "TRAIN_BATCHES = 64 # how many samples will be trained within one mini-batch, depends on your hardware\n",
    "PRE_TRAINED_ITERS = 0 # [0, infinity) how many batches the model has been trained before\n",
    "SKIP_TRAINED_DATA = 0 # [0, infinity) if this is a resumed training, how many input data will be skipped\n",
    "TRAIN_ITERS = 1000 # [0, infinity) how many batches the model will be trained\n",
    "TEST_BATCHES = 100 # how many samples will be tested within one mini-batch\n",
    "TEST_ITERS = 10000 # how many batches the model will be tested\n",
    "\n",
    "ROOT_FOLDER = os.path.join(os.path.expanduser('~'), 'python', 'tutorial_data','zero','param') # folder stores the loss/accuracy log\n",
    "DATA_FOLDER = os.path.join(os.path.expanduser('~'), 'python', 'tutorial_data','zero')\n",
    "TRAIN_DATA = os.path.join(DATA_FOLDER,'tr_data') # db folder stores the preprocessed games\n",
    "TEST_DATA = os.path.join(DATA_FOLDER,'test_data') # db folder stores the preprocessed games\n",
    "\n",
    "# if this is a resumed training, where to load the init_param from\n",
    "LOAD_FOLDER = os.path.join(ROOT_FOLDER, \"res={}-k={}-iter={}\".format(NUM_RES_BLOCKS,FILTERS,PRE_TRAINED_ITERS))\n",
    "\n",
    "# if the model will be saved for future resume training, where to store it\n",
    "SAVE_FOLDER = os.path.join(ROOT_FOLDER, \"res={}-k={}-iter={}\".format(NUM_RES_BLOCKS,FILTERS,PRE_TRAINED_ITERS+TRAIN_ITERS))\n",
    "\n",
    "workspace.ResetWorkspace(ROOT_FOLDER)\n",
    "\n",
    "print('Training model from {} to {} iterations'.format(PRE_TRAINED_ITERS,PRE_TRAINED_ITERS+TRAIN_ITERS))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AlphaGo Neural Network Architecture\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Input\n",
    ">The input to the neural network is a 19 × 19 × 17 image stack\n",
    "comprising 17 binary feature planes. 8 feature planes $X_t$ consist of binary values indicating the\n",
    "presence of the current player’s stones ($X_t^i = 1$ if intersection $i$ contains a stone of the player’s\n",
    "colour at time-step $t$; $0$ if the intersection is empty, contains an opponent stone, or if $t < 0$). A\n",
    "further 8 feature planes, $Y_t$ , represent the corresponding features for the opponent’s stones. The\n",
    "final feature plane, $C$, represents the colour to play, and has a constant value of either 1 if black\n",
    "is to play or 0 if white is to play. These planes are concatenated together to give input features\n",
    "$s_t = [X_t , Y_t , X_{t−1} , Y_{t−1} , ..., X_{t−7} , Y_{t−7} , C]$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from modelingZero import AddInput"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DCNN\n",
    ">The input features $S_t$ are processed by a residual tower that consists of a single convolutional block followed by either 19 or 39 residual blocks 4. The convolutional block applies the following modules:\n",
    "1. A convolution of 256 filters of kernel size 3 x 3 with stride 1\n",
    "2. Batch normalisation 18\n",
    "3. A rectifier non-linearity\n",
    "\n",
    ">Each residual block applies the following modules sequentially to its input:\n",
    "1. A convolution of 256 filters of kernel size 3 x 3 with stride 1\n",
    "2. Batch normalisation\n",
    "3. A rectifier non-linearity\n",
    "4. A convolution of 256 filters of kernel size 3 x 3 with stride 1\n",
    "5. Batch normalisation\n",
    "6. A skip connection that adds the input to the block\n",
    "7. A rectifier non-linearity\n",
    "\n",
    ">The output of the residual tower is passed into two separate “heads” for computing the policy and value respectively. The policy head applies the following modules:\n",
    "1. A convolution of 2 filters of kernel size 1 x 1 with stride 1\n",
    "2. Batch normalisation\n",
    "3. A rectifier non-linearity\n",
    "4. A fully connected linear layer that outputs a vector of size 192 + 1 = 362 corresponding to logit probabilities for all intersections and the pass move\n",
    "\n",
    ">The value head applies the following modules:\n",
    "1. A convolution of 1 filter of kernel size 1 x 1 with stride 1\n",
    "2. Batch normalisation\n",
    "3. A rectifier non-linearity\n",
    "4. A fully connected linear layer to a hidden layer of size 256\n",
    "5. A rectifier non-linearity\n",
    "6. A fully connected linear layer to a scalar\n",
    "7. A tanh non-linearity outputting a scalar in the range `[-1; 1]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from modelingZero import AddResNetModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy\n",
    "Please note predict is 4 dimensional tensor in shape of N x 1 x 19 x 19, and label is 2 dimensional tensor in shape of N x 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from modelingZero import AddAccuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Operator (Backward Propagation)\n",
    "\n",
    ">A game terminates at step $T$ when both players pass, when the search value drops below a \n",
    "resignation threshold (`10%`), or when the game exceeds a maximum length (`722 steps`); \n",
    "the game is then scored to give a final reward of $r_T\\in\\{-1,+1\\}$ (see\n",
    "Methods for details). The data for each time-step $t$ is stored as $(s_t, \\pi_t, z_t)$ \n",
    "where $z_t = \\pm r_T$ is the game winner from the perspective of the current player at step $t$.\n",
    "In parallel (Figure 1b), new network parameters $\\theta_i$ are trained from data $(s,\\pi,z)$\n",
    "sampled uniformly among all time-steps of the last iteration(s) of self-play. The neural \n",
    "network $(p,v) = f_{\\theta _i}(s)$ is adjusted to minimise the error between the predicted \n",
    "value $v$ and the self-play winner $z$, and to maximise the similarity of the neural network \n",
    "move probabilities $p$ to the search probabilities $\\pi$. Specifically, the parameters $\\theta$\n",
    "are adjusted by gradient descent on a loss function $l$ that sums over mean-squared error and\n",
    "cross-entropy losses respectively,\n",
    "\n",
    ">>$(p,v) = f_\\theta(s), l = (z - v)^2 \\pi^T \\log p + c|| \\theta ||^2$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from modelingZero import AddTrainingOperators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trace the training progress\n",
    "Print 'accuracy' and 'loss' to file and we can monitor them elsewhere."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from modelingZero import AddBookkeepingOperators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the actual network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "arg_scope = {\"order\": \"NCHW\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Skip model only has DBInput to waste the input\n",
    "skip_model = model_helper.ModelHelper(name=\"skip_model\", arg_scope=arg_scope, init_params=True)\n",
    "_d, _l, _r = AddInput(\n",
    "    skip_model, batch_size=TRAIN_BATCHES,\n",
    "    db=TRAIN_DATA,\n",
    "    db_type='leveldb')\n",
    "# Initialize params and create network\n",
    "workspace.RunNetOnce(skip_model.param_init_net)\n",
    "workspace.CreateNet(skip_model.net, overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:You are creating an op that the ModelHelper does not recognize: PadImage.\n",
      "WARNING:root:You are creating an op that the ModelHelper does not recognize: Normalize.\n",
      "WARNING:root:You are creating an op that the ModelHelper does not recognize: PadImage.\n",
      "WARNING:root:You are creating an op that the ModelHelper does not recognize: Normalize.\n",
      "WARNING:root:You are creating an op that the ModelHelper does not recognize: PadImage.\n",
      "WARNING:root:You are creating an op that the ModelHelper does not recognize: Normalize.\n",
      "WARNING:root:You are creating an op that the ModelHelper does not recognize: PadImage.\n",
      "WARNING:root:You are creating an op that the ModelHelper does not recognize: Normalize.\n",
      "WARNING:root:You are creating an op that the ModelHelper does not recognize: PadImage.\n",
      "WARNING:root:You are creating an op that the ModelHelper does not recognize: Normalize.\n",
      "WARNING:root:You are creating an op that the ModelHelper does not recognize: PadImage.\n",
      "WARNING:root:You are creating an op that the ModelHelper does not recognize: Normalize.\n",
      "WARNING:root:You are creating an op that the ModelHelper does not recognize: PadImage.\n",
      "WARNING:root:You are creating an op that the ModelHelper does not recognize: Normalize.\n",
      "WARNING:root:You are creating an op that the ModelHelper does not recognize: PadImage.\n",
      "WARNING:root:You are creating an op that the ModelHelper does not recognize: Normalize.\n",
      "WARNING:root:You are creating an op that the ModelHelper does not recognize: PadImage.\n",
      "WARNING:root:You are creating an op that the ModelHelper does not recognize: Normalize.\n",
      "WARNING:root:You are creating an op that the ModelHelper does not recognize: Normalize.\n",
      "WARNING:root:You are creating an op that the ModelHelper does not recognize: Normalize.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train Net: DBInput ==> Predict Net ==> Loss ==> Backward Propergation\n",
    "with core.DeviceScope(device_opts):\n",
    "    train_model = model_helper.ModelHelper(name=\"policy_train\", arg_scope=arg_scope, init_params=True)\n",
    "    data, label, reward = AddInput(\n",
    "        train_model, batch_size=TRAIN_BATCHES,\n",
    "        db=TRAIN_DATA,\n",
    "        db_type='leveldb')\n",
    "    predict, value = AddResNetModel(train_model, data, num_blocks=NUM_RES_BLOCKS, filters=FILTERS, dim_in=17)\n",
    "    AddTrainingOperators(train_model, predict, label, value, reward, base_lr=BASE_LR)\n",
    "    AddBookkeepingOperators(train_model)\n",
    "# Initialize params and create network\n",
    "workspace.RunNetOnce(train_model.param_init_net)\n",
    "workspace.CreateNet(train_model.net, overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:You are creating an op that the ModelHelper does not recognize: PadImage.\n",
      "WARNING:root:You are creating an op that the ModelHelper does not recognize: Normalize.\n",
      "WARNING:root:You are creating an op that the ModelHelper does not recognize: PadImage.\n",
      "WARNING:root:You are creating an op that the ModelHelper does not recognize: Normalize.\n",
      "WARNING:root:You are creating an op that the ModelHelper does not recognize: PadImage.\n",
      "WARNING:root:You are creating an op that the ModelHelper does not recognize: Normalize.\n",
      "WARNING:root:You are creating an op that the ModelHelper does not recognize: PadImage.\n",
      "WARNING:root:You are creating an op that the ModelHelper does not recognize: Normalize.\n",
      "WARNING:root:You are creating an op that the ModelHelper does not recognize: PadImage.\n",
      "WARNING:root:You are creating an op that the ModelHelper does not recognize: Normalize.\n",
      "WARNING:root:You are creating an op that the ModelHelper does not recognize: PadImage.\n",
      "WARNING:root:You are creating an op that the ModelHelper does not recognize: Normalize.\n",
      "WARNING:root:You are creating an op that the ModelHelper does not recognize: PadImage.\n",
      "WARNING:root:You are creating an op that the ModelHelper does not recognize: Normalize.\n",
      "WARNING:root:You are creating an op that the ModelHelper does not recognize: PadImage.\n",
      "WARNING:root:You are creating an op that the ModelHelper does not recognize: Normalize.\n",
      "WARNING:root:You are creating an op that the ModelHelper does not recognize: PadImage.\n",
      "WARNING:root:You are creating an op that the ModelHelper does not recognize: Normalize.\n",
      "WARNING:root:You are creating an op that the ModelHelper does not recognize: Normalize.\n",
      "WARNING:root:You are creating an op that the ModelHelper does not recognize: Normalize.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test Net: DBInput ==> Predict Net ==> Accuracy\n",
    "with core.DeviceScope(device_opts):\n",
    "    test_model = model_helper.ModelHelper(name=\"policy_test\", arg_scope=arg_scope, init_params=False)\n",
    "    data, label, reward = AddInput(\n",
    "        test_model, batch_size=TEST_BATCHES,\n",
    "        db=TEST_DATA,\n",
    "        db_type='leveldb')\n",
    "    predict, value = AddResNetModel(test_model, data, num_blocks=NUM_RES_BLOCKS, filters=FILTERS, dim_in=17)\n",
    "    AddAccuracy(test_model, predict, label)\n",
    "# Initialize params and create network\n",
    "workspace.RunNetOnce(test_model.param_init_net)\n",
    "workspace.CreateNet(test_model.net, overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deploy Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:You are creating an op that the ModelHelper does not recognize: PadImage.\n",
      "WARNING:root:You are creating an op that the ModelHelper does not recognize: Normalize.\n",
      "WARNING:root:You are creating an op that the ModelHelper does not recognize: PadImage.\n",
      "WARNING:root:You are creating an op that the ModelHelper does not recognize: Normalize.\n",
      "WARNING:root:You are creating an op that the ModelHelper does not recognize: PadImage.\n",
      "WARNING:root:You are creating an op that the ModelHelper does not recognize: Normalize.\n",
      "WARNING:root:You are creating an op that the ModelHelper does not recognize: PadImage.\n",
      "WARNING:root:You are creating an op that the ModelHelper does not recognize: Normalize.\n",
      "WARNING:root:You are creating an op that the ModelHelper does not recognize: PadImage.\n",
      "WARNING:root:You are creating an op that the ModelHelper does not recognize: Normalize.\n",
      "WARNING:root:You are creating an op that the ModelHelper does not recognize: PadImage.\n",
      "WARNING:root:You are creating an op that the ModelHelper does not recognize: Normalize.\n",
      "WARNING:root:You are creating an op that the ModelHelper does not recognize: PadImage.\n",
      "WARNING:root:You are creating an op that the ModelHelper does not recognize: Normalize.\n",
      "WARNING:root:You are creating an op that the ModelHelper does not recognize: PadImage.\n",
      "WARNING:root:You are creating an op that the ModelHelper does not recognize: Normalize.\n",
      "WARNING:root:You are creating an op that the ModelHelper does not recognize: PadImage.\n",
      "WARNING:root:You are creating an op that the ModelHelper does not recognize: Normalize.\n",
      "WARNING:root:You are creating an op that the ModelHelper does not recognize: Normalize.\n",
      "WARNING:root:You are creating an op that the ModelHelper does not recognize: Normalize.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train Net: Blob('data') ==> Predict Net ==> Blob('predict')\n",
    "with core.DeviceScope(device_opts):\n",
    "    deploy_model = model_helper.ModelHelper(name=\"policy_deploy\", arg_scope=arg_scope, init_params=False)\n",
    "    AddResNetModel(deploy_model, 'data', num_blocks=NUM_RES_BLOCKS, filters=FILTERS, dim_in=17)\n",
    "# Initialize params and create network\n",
    "workspace.RunNetOnce(deploy_model.param_init_net)\n",
    "workspace.CreateNet(deploy_model.net, overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the training and testing\n",
    "### resume from last training\n",
    "    Training a multi-level CNN takes quite a long time. To pause-and-resume the training, set the PRE_TRAINED_ITERS so the program will start from where last time it was."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import caffe2.python.predictor.predictor_exporter as pe\n",
    "\n",
    "# construct the model to be exported\n",
    "pe_meta = pe.PredictorExportMeta(\n",
    "    predict_net=deploy_model.net.Proto(),\n",
    "    parameters=[str(b) for b in deploy_model.params], \n",
    "    inputs=[\"data\"],\n",
    "    outputs=[\"predict\"],\n",
    ")\n",
    "\n",
    "if PRE_TRAINED_ITERS > 0:\n",
    "    #load_net(LOAD_INIT_NET, LOAD_PREDICT_NET)\n",
    "    # load the predict net\n",
    "    with core.DeviceScope(device_opts):\n",
    "        deploy_model.net = pe.prepare_prediction_net(os.path.join(LOAD_FOLDER, \"policy_model.minidb\"), \"minidb\")\n",
    "    print('Params loaded from {}'.format(LOAD_FOLDER))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-5b97c26d96fe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;31m# Now, run the network\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTRAIN_ITERS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mworkspace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRunNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0maccuracy\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mworkspace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFetchBlob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mworkspace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFetchBlob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/caffe2/python/workspace.py\u001b[0m in \u001b[0;36mRunNet\u001b[0;34m(name, num_iter, allow_fail)\u001b[0m\n\u001b[1;32m    199\u001b[0m         \u001b[0mC\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mWorkspace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_last_failed_op_net_position\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m         \u001b[0mGetNetName\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m         \u001b[0mStringifyNetName\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_fail\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m     )\n\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/caffe2/python/workspace.py\u001b[0m in \u001b[0;36mCallWithExceptionIntercept\u001b[0;34m(func, op_id_fetcher, net_name, *args, **kwargs)\u001b[0m\n\u001b[1;32m    164\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mCallWithExceptionIntercept\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_id_fetcher\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnet_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m         \u001b[0mop_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mop_id_fetcher\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#%%capture output # Jupyter magic command to capture the output\n",
    "\n",
    "if TRAIN_ITERS > 0:\n",
    "    # skip the data which should not be trained again\n",
    "    for i in range(SKIP_TRAINED_DATA):\n",
    "        workspace.RunNet(skip_model.net)\n",
    "    \n",
    "    # set the number of iterations and track the accuracy & loss\n",
    "    accuracy = np.zeros(TRAIN_ITERS)\n",
    "    loss = np.zeros(TRAIN_ITERS)\n",
    "    loss1 = np.zeros(TRAIN_ITERS)\n",
    "    loss2 = np.zeros(TRAIN_ITERS)\n",
    "    # Now, run the network \n",
    "    for i in range(TRAIN_ITERS):\n",
    "        workspace.RunNet(train_model.net)\n",
    "        accuracy[i] = workspace.FetchBlob('accuracy')\n",
    "        loss[i] = workspace.FetchBlob('loss')\n",
    "        loss1[i] = workspace.FetchBlob('loss1')\n",
    "        loss2[i] = workspace.FetchBlob('loss2')\n",
    "        # checkpoint every 10000 iterations\n",
    "        if i > 0 and i % 10000 == 0:\n",
    "            if not os.path.exists(SAVE_FOLDER):\n",
    "                os.makedirs(SAVE_FOLDER)\n",
    "            pe.save_to_db(\"minidb\", os.path.join(SAVE_FOLDER, \"policy_model_checkpoint_{}.minidb\".format(PRE_TRAINED_ITERS+i)), pe_meta)\n",
    "            print('Checkpoint {} saved to {}'.format(PRE_TRAINED_ITERS+i,SAVE_FOLDER))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fe3893177d0>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD8CAYAAABn919SAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fe3acd182d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# After the execution is done, plot the values.\n",
    "pyplot.plot(loss1, 'b')\n",
    "pyplot.plot(loss2, 'g')\n",
    "pyplot.plot(accuracy, 'r')\n",
    "pyplot.plot(loss, 'pink')\n",
    "pyplot.legend(('Loss', 'Accuracy'), loc='upper right')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_accuracy = np.zeros(TEST_ITERS)\n",
    "for i in range(TEST_ITERS):\n",
    "    workspace.RunNet(test_model.net)\n",
    "    test_accuracy[i] = workspace.FetchBlob('accuracy')\n",
    "# After the execution is done, let's plot the values.\n",
    "pyplot.plot(test_accuracy, 'r')\n",
    "pyplot.title('Acuracy over test batches.')\n",
    "print('test_accuracy: %f' % test_accuracy.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the work for future use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if TRAIN_ITERS > 0:\n",
    "    if not os.path.exists(SAVE_FOLDER):\n",
    "        os.makedirs(SAVE_FOLDER)\n",
    "    # save the model to a file. Use minidb as the file format\n",
    "    pe.save_to_db(\"minidb\", os.path.join(SAVE_FOLDER, \"policy_model.minidb\"), pe_meta)\n",
    "    print('Params saved to {}'.format(SAVE_FOLDER))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "workspace.RunNet(train_model.net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[ nan,  nan,  nan, ...,  nan,  nan,  nan],\n",
       "         [ nan,  nan,  nan, ...,  nan,  nan,  nan],\n",
       "         [ nan,  nan,  nan, ...,  nan,  nan,  nan],\n",
       "         ..., \n",
       "         [ nan,  nan,  nan, ...,  nan,  nan,  nan],\n",
       "         [ nan,  nan,  nan, ...,  nan,  nan,  nan],\n",
       "         [ nan,  nan,  nan, ...,  nan,  nan,  nan]],\n",
       "\n",
       "        [[ nan,  nan,  nan, ...,  nan,  nan,  nan],\n",
       "         [ nan,  nan,  nan, ...,  nan,  nan,  nan],\n",
       "         [ nan,  nan,  nan, ...,  nan,  nan,  nan],\n",
       "         ..., \n",
       "         [ nan,  nan,  nan, ...,  nan,  nan,  nan],\n",
       "         [ nan,  nan,  nan, ...,  nan,  nan,  nan],\n",
       "         [ nan,  nan,  nan, ...,  nan,  nan,  nan]],\n",
       "\n",
       "        [[ nan,  nan,  nan, ...,  nan,  nan,  nan],\n",
       "         [ nan,  nan,  nan, ...,  nan,  nan,  nan],\n",
       "         [ nan,  nan,  nan, ...,  nan,  nan,  nan],\n",
       "         ..., \n",
       "         [ nan,  nan,  nan, ...,  nan,  nan,  nan],\n",
       "         [ nan,  nan,  nan, ...,  nan,  nan,  nan],\n",
       "         [ nan,  nan,  nan, ...,  nan,  nan,  nan]],\n",
       "\n",
       "        ..., \n",
       "        [[ nan,  nan,  nan, ...,  nan,  nan,  nan],\n",
       "         [ nan,  nan,  nan, ...,  nan,  nan,  nan],\n",
       "         [ nan,  nan,  nan, ...,  nan,  nan,  nan],\n",
       "         ..., \n",
       "         [ nan,  nan,  nan, ...,  nan,  nan,  nan],\n",
       "         [ nan,  nan,  nan, ...,  nan,  nan,  nan],\n",
       "         [ nan,  nan,  nan, ...,  nan,  nan,  nan]],\n",
       "\n",
       "        [[ nan,  nan,  nan, ...,  nan,  nan,  nan],\n",
       "         [ nan,  nan,  nan, ...,  nan,  nan,  nan],\n",
       "         [ nan,  nan,  nan, ...,  nan,  nan,  nan],\n",
       "         ..., \n",
       "         [ nan,  nan,  nan, ...,  nan,  nan,  nan],\n",
       "         [ nan,  nan,  nan, ...,  nan,  nan,  nan],\n",
       "         [ nan,  nan,  nan, ...,  nan,  nan,  nan]],\n",
       "\n",
       "        [[ nan,  nan,  nan, ...,  nan,  nan,  nan],\n",
       "         [ nan,  nan,  nan, ...,  nan,  nan,  nan],\n",
       "         [ nan,  nan,  nan, ...,  nan,  nan,  nan],\n",
       "         ..., \n",
       "         [ nan,  nan,  nan, ...,  nan,  nan,  nan],\n",
       "         [ nan,  nan,  nan, ...,  nan,  nan,  nan],\n",
       "         [ nan,  nan,  nan, ...,  nan,  nan,  nan]]],\n",
       "\n",
       "\n",
       "       [[[ nan,  nan,  nan, ...,  nan,  nan,  nan],\n",
       "         [ nan,  nan,  nan, ...,  nan,  nan,  nan],\n",
       "         [ nan,  nan,  nan, ...,  nan,  nan,  nan],\n",
       "         ..., \n",
       "         [ nan,  nan,  nan, ...,  nan,  nan,  nan],\n",
       "         [ nan,  nan,  nan, ...,  nan,  nan,  nan],\n",
       "         [ nan,  nan,  nan, ...,  nan,  nan,  nan]],\n",
       "\n",
       "        [[ nan,  nan,  nan, ...,  nan,  nan,  nan],\n",
       "         [ nan,  nan,  nan, ...,  nan,  nan,  nan],\n",
       "         [ nan,  nan,  nan, ...,  nan,  nan,  nan],\n",
       "         ..., \n",
       "         [ nan,  nan,  nan, ...,  nan,  nan,  nan],\n",
       "         [ nan,  nan,  nan, ...,  nan,  nan,  nan],\n",
       "         [ nan,  nan,  nan, ...,  nan,  nan,  nan]],\n",
       "\n",
       "        [[ nan,  nan,  nan, ...,  nan,  nan,  nan],\n",
       "         [ nan,  nan,  nan, ...,  nan,  nan,  nan],\n",
       "         [ nan,  nan,  nan, ...,  nan,  nan,  nan],\n",
       "         ..., \n",
       "         [ nan,  nan,  nan, ...,  nan,  nan,  nan],\n",
       "         [ nan,  nan,  nan, ...,  nan,  nan,  nan],\n",
       "         [ nan,  nan,  nan, ...,  nan,  nan,  nan]],\n",
       "\n",
       "        ..., \n",
       "        [[ nan,  nan,  nan, ...,  nan,  nan,  nan],\n",
       "         [ nan,  nan,  nan, ...,  nan,  nan,  nan],\n",
       "         [ nan,  nan,  nan, ...,  nan,  nan,  nan],\n",
       "         ..., \n",
       "         [ nan,  nan,  nan, ...,  nan,  nan,  nan],\n",
       "         [ nan,  nan,  nan, ...,  nan,  nan,  nan],\n",
       "         [ nan,  nan,  nan, ...,  nan,  nan,  nan]],\n",
       "\n",
       "        [[ nan,  nan,  nan, ...,  nan,  nan,  nan],\n",
       "         [ nan,  nan,  nan, ...,  nan,  nan,  nan],\n",
       "         [ nan,  nan,  nan, ...,  nan,  nan,  nan],\n",
       "         ..., \n",
       "         [ nan,  nan,  nan, ...,  nan,  nan,  nan],\n",
       "         [ nan,  nan,  nan, ...,  nan,  nan,  nan],\n",
       "         [ nan,  nan,  nan, ...,  nan,  nan,  nan]],\n",
       "\n",
       "        [[ nan,  nan,  nan, ...,  nan,  nan,  nan],\n",
       "         [ nan,  nan,  nan, ...,  nan,  nan,  nan],\n",
       "         [ nan,  nan,  nan, ...,  nan,  nan,  nan],\n",
       "         ..., \n",
       "         [ nan,  nan,  nan, ...,  nan,  nan,  nan],\n",
       "         [ nan,  nan,  nan, ...,  nan,  nan,  nan],\n",
       "         [ nan,  nan,  nan, ...,  nan,  nan,  nan]]],\n",
       "\n",
       "\n",
       "       [[[ nan,  nan,  nan, ...,  nan,  nan,  nan],\n",
       "         [ nan,  nan,  nan, ...,  nan,  nan,  nan],\n",
       "         [ nan,  nan,  nan, ...,  nan,  nan,  nan],\n",
       "         ..., \n",
       "         [ nan,  nan,  nan, ...,  nan,  nan,  nan],\n",
       "         [ nan,  nan,  nan, ...,  nan,  nan,  nan],\n",
       "         [ nan,  nan,  nan, ...,  nan,  nan,  nan]],\n",
       "\n",
       "        [[ nan,  nan,  nan, ...,  nan,  nan,  nan],\n",
       "         [ nan,  nan,  nan, ...,  nan,  nan,  nan],\n",
       "         [ nan,  nan,  nan, ...,  nan,  nan,  nan],\n",
       "         ..., \n",
       "         [ nan,  nan,  nan, ...,  nan,  nan,  nan],\n",
       "         [ nan,  nan,  nan, ...,  nan,  nan,  nan],\n",
       "         [ nan,  nan,  nan, ...,  nan,  nan,  nan]],\n",
       "\n",
       "        [[ nan,  nan,  nan, ...,  nan,  nan,  nan],\n",
       "         [ nan,  nan,  nan, ...,  nan,  nan,  nan],\n",
       "         [ nan,  nan,  nan, ...,  nan,  nan,  nan],\n",
       "         ..., \n",
       "         [ nan,  nan,  nan, ...,  nan,  nan,  nan],\n",
       "         [ nan,  nan,  nan, ...,  nan,  nan,  nan],\n",
       "         [ nan,  nan,  nan, ...,  nan,  nan,  nan]],\n",
       "\n",
       "        ..., \n",
       "        [[ nan,  nan,  nan, ...,  nan,  nan,  nan],\n",
       "         [ nan,  nan,  nan, ...,  nan,  nan,  nan],\n",
       "         [ nan,  nan,  nan, ...,  nan,  nan,  nan],\n",
       "         ..., \n",
       "         [ nan,  nan,  nan, ...,  nan,  nan,  nan],\n",
       "         [ nan,  nan,  nan, ...,  nan,  nan,  nan],\n",
       "         [ nan,  nan,  nan, ...,  nan,  nan,  nan]],\n",
       "\n",
       "        [[ nan,  nan,  nan, ...,  nan,  nan,  nan],\n",
       "         [ nan,  nan,  nan, ...,  nan,  nan,  nan],\n",
       "         [ nan,  nan,  nan, ...,  nan,  nan,  nan],\n",
       "         ..., \n",
       "         [ nan,  nan,  nan, ...,  nan,  nan,  nan],\n",
       "         [ nan,  nan,  nan, ...,  nan,  nan,  nan],\n",
       "         [ nan,  nan,  nan, ...,  nan,  nan,  nan]],\n",
       "\n",
       "        [[ nan,  nan,  nan, ...,  nan,  nan,  nan],\n",
       "         [ nan,  nan,  nan, ...,  nan,  nan,  nan],\n",
       "         [ nan,  nan,  nan, ...,  nan,  nan,  nan],\n",
       "         ..., \n",
       "         [ nan,  nan,  nan, ...,  nan,  nan,  nan],\n",
       "         [ nan,  nan,  nan, ...,  nan,  nan,  nan],\n",
       "         [ nan,  nan,  nan, ...,  nan,  nan,  nan]]],\n",
       "\n",
       "\n",
       "       ..., \n",
       "       [[[ nan,  nan,  nan, ...,  nan,  nan,  nan],\n",
       "         [ nan,  nan,  nan, ...,  nan,  nan,  nan],\n",
       "         [ nan,  nan,  nan, ...,  nan,  nan,  nan],\n",
       "         ..., \n",
       "         [ nan,  nan,  nan, ...,  nan,  nan,  nan],\n",
       "         [ nan,  nan,  nan, ...,  nan,  nan,  nan],\n",
       "         [ nan,  nan,  nan, ...,  nan,  nan,  nan]],\n",
       "\n",
       "        [[ nan,  nan,  nan, ...,  nan,  nan,  nan],\n",
       "         [ nan,  nan,  nan, ...,  nan,  nan,  nan],\n",
       "         [ nan,  nan,  nan, ...,  nan,  nan,  nan],\n",
       "         ..., \n",
       "         [ nan,  nan,  nan, ...,  nan,  nan,  nan],\n",
       "         [ nan,  nan,  nan, ...,  nan,  nan,  nan],\n",
       "         [ nan,  nan,  nan, ...,  nan,  nan,  nan]],\n",
       "\n",
       "        [[ nan,  nan,  nan, ...,  nan,  nan,  nan],\n",
       "         [ nan,  nan,  nan, ...,  nan,  nan,  nan],\n",
       "         [ nan,  nan,  nan, ...,  nan,  nan,  nan],\n",
       "         ..., \n",
       "         [ nan,  nan,  nan, ...,  nan,  nan,  nan],\n",
       "         [ nan,  nan,  nan, ...,  nan,  nan,  nan],\n",
       "         [ nan,  nan,  nan, ...,  nan,  nan,  nan]],\n",
       "\n",
       "        ..., \n",
       "        [[ nan,  nan,  nan, ...,  nan,  nan,  nan],\n",
       "         [ nan,  nan,  nan, ...,  nan,  nan,  nan],\n",
       "         [ nan,  nan,  nan, ...,  nan,  nan,  nan],\n",
       "         ..., \n",
       "         [ nan,  nan,  nan, ...,  nan,  nan,  nan],\n",
       "         [ nan,  nan,  nan, ...,  nan,  nan,  nan],\n",
       "         [ nan,  nan,  nan, ...,  nan,  nan,  nan]],\n",
       "\n",
       "        [[ nan,  nan,  nan, ...,  nan,  nan,  nan],\n",
       "         [ nan,  nan,  nan, ...,  nan,  nan,  nan],\n",
       "         [ nan,  nan,  nan, ...,  nan,  nan,  nan],\n",
       "         ..., \n",
       "         [ nan,  nan,  nan, ...,  nan,  nan,  nan],\n",
       "         [ nan,  nan,  nan, ...,  nan,  nan,  nan],\n",
       "         [ nan,  nan,  nan, ...,  nan,  nan,  nan]],\n",
       "\n",
       "        [[ nan,  nan,  nan, ...,  nan,  nan,  nan],\n",
       "         [ nan,  nan,  nan, ...,  nan,  nan,  nan],\n",
       "         [ nan,  nan,  nan, ...,  nan,  nan,  nan],\n",
       "         ..., \n",
       "         [ nan,  nan,  nan, ...,  nan,  nan,  nan],\n",
       "         [ nan,  nan,  nan, ...,  nan,  nan,  nan],\n",
       "         [ nan,  nan,  nan, ...,  nan,  nan,  nan]]],\n",
       "\n",
       "\n",
       "       [[[ nan,  nan,  nan, ...,  nan,  nan,  nan],\n",
       "         [ nan,  nan,  nan, ...,  nan,  nan,  nan],\n",
       "         [ nan,  nan,  nan, ...,  nan,  nan,  nan],\n",
       "         ..., \n",
       "         [ nan,  nan,  nan, ...,  nan,  nan,  nan],\n",
       "         [ nan,  nan,  nan, ...,  nan,  nan,  nan],\n",
       "         [ nan,  nan,  nan, ...,  nan,  nan,  nan]],\n",
       "\n",
       "        [[ nan,  nan,  nan, ...,  nan,  nan,  nan],\n",
       "         [ nan,  nan,  nan, ...,  nan,  nan,  nan],\n",
       "         [ nan,  nan,  nan, ...,  nan,  nan,  nan],\n",
       "         ..., \n",
       "         [ nan,  nan,  nan, ...,  nan,  nan,  nan],\n",
       "         [ nan,  nan,  nan, ...,  nan,  nan,  nan],\n",
       "         [ nan,  nan,  nan, ...,  nan,  nan,  nan]],\n",
       "\n",
       "        [[ nan,  nan,  nan, ...,  nan,  nan,  nan],\n",
       "         [ nan,  nan,  nan, ...,  nan,  nan,  nan],\n",
       "         [ nan,  nan,  nan, ...,  nan,  nan,  nan],\n",
       "         ..., \n",
       "         [ nan,  nan,  nan, ...,  nan,  nan,  nan],\n",
       "         [ nan,  nan,  nan, ...,  nan,  nan,  nan],\n",
       "         [ nan,  nan,  nan, ...,  nan,  nan,  nan]],\n",
       "\n",
       "        ..., \n",
       "        [[ nan,  nan,  nan, ...,  nan,  nan,  nan],\n",
       "         [ nan,  nan,  nan, ...,  nan,  nan,  nan],\n",
       "         [ nan,  nan,  nan, ...,  nan,  nan,  nan],\n",
       "         ..., \n",
       "         [ nan,  nan,  nan, ...,  nan,  nan,  nan],\n",
       "         [ nan,  nan,  nan, ...,  nan,  nan,  nan],\n",
       "         [ nan,  nan,  nan, ...,  nan,  nan,  nan]],\n",
       "\n",
       "        [[ nan,  nan,  nan, ...,  nan,  nan,  nan],\n",
       "         [ nan,  nan,  nan, ...,  nan,  nan,  nan],\n",
       "         [ nan,  nan,  nan, ...,  nan,  nan,  nan],\n",
       "         ..., \n",
       "         [ nan,  nan,  nan, ...,  nan,  nan,  nan],\n",
       "         [ nan,  nan,  nan, ...,  nan,  nan,  nan],\n",
       "         [ nan,  nan,  nan, ...,  nan,  nan,  nan]],\n",
       "\n",
       "        [[ nan,  nan,  nan, ...,  nan,  nan,  nan],\n",
       "         [ nan,  nan,  nan, ...,  nan,  nan,  nan],\n",
       "         [ nan,  nan,  nan, ...,  nan,  nan,  nan],\n",
       "         ..., \n",
       "         [ nan,  nan,  nan, ...,  nan,  nan,  nan],\n",
       "         [ nan,  nan,  nan, ...,  nan,  nan,  nan],\n",
       "         [ nan,  nan,  nan, ...,  nan,  nan,  nan]]],\n",
       "\n",
       "\n",
       "       [[[ nan,  nan,  nan, ...,  nan,  nan,  nan],\n",
       "         [ nan,  nan,  nan, ...,  nan,  nan,  nan],\n",
       "         [ nan,  nan,  nan, ...,  nan,  nan,  nan],\n",
       "         ..., \n",
       "         [ nan,  nan,  nan, ...,  nan,  nan,  nan],\n",
       "         [ nan,  nan,  nan, ...,  nan,  nan,  nan],\n",
       "         [ nan,  nan,  nan, ...,  nan,  nan,  nan]],\n",
       "\n",
       "        [[ nan,  nan,  nan, ...,  nan,  nan,  nan],\n",
       "         [ nan,  nan,  nan, ...,  nan,  nan,  nan],\n",
       "         [ nan,  nan,  nan, ...,  nan,  nan,  nan],\n",
       "         ..., \n",
       "         [ nan,  nan,  nan, ...,  nan,  nan,  nan],\n",
       "         [ nan,  nan,  nan, ...,  nan,  nan,  nan],\n",
       "         [ nan,  nan,  nan, ...,  nan,  nan,  nan]],\n",
       "\n",
       "        [[ nan,  nan,  nan, ...,  nan,  nan,  nan],\n",
       "         [ nan,  nan,  nan, ...,  nan,  nan,  nan],\n",
       "         [ nan,  nan,  nan, ...,  nan,  nan,  nan],\n",
       "         ..., \n",
       "         [ nan,  nan,  nan, ...,  nan,  nan,  nan],\n",
       "         [ nan,  nan,  nan, ...,  nan,  nan,  nan],\n",
       "         [ nan,  nan,  nan, ...,  nan,  nan,  nan]],\n",
       "\n",
       "        ..., \n",
       "        [[ nan,  nan,  nan, ...,  nan,  nan,  nan],\n",
       "         [ nan,  nan,  nan, ...,  nan,  nan,  nan],\n",
       "         [ nan,  nan,  nan, ...,  nan,  nan,  nan],\n",
       "         ..., \n",
       "         [ nan,  nan,  nan, ...,  nan,  nan,  nan],\n",
       "         [ nan,  nan,  nan, ...,  nan,  nan,  nan],\n",
       "         [ nan,  nan,  nan, ...,  nan,  nan,  nan]],\n",
       "\n",
       "        [[ nan,  nan,  nan, ...,  nan,  nan,  nan],\n",
       "         [ nan,  nan,  nan, ...,  nan,  nan,  nan],\n",
       "         [ nan,  nan,  nan, ...,  nan,  nan,  nan],\n",
       "         ..., \n",
       "         [ nan,  nan,  nan, ...,  nan,  nan,  nan],\n",
       "         [ nan,  nan,  nan, ...,  nan,  nan,  nan],\n",
       "         [ nan,  nan,  nan, ...,  nan,  nan,  nan]],\n",
       "\n",
       "        [[ nan,  nan,  nan, ...,  nan,  nan,  nan],\n",
       "         [ nan,  nan,  nan, ...,  nan,  nan,  nan],\n",
       "         [ nan,  nan,  nan, ...,  nan,  nan,  nan],\n",
       "         ..., \n",
       "         [ nan,  nan,  nan, ...,  nan,  nan,  nan],\n",
       "         [ nan,  nan,  nan, ...,  nan,  nan,  nan],\n",
       "         [ nan,  nan,  nan, ...,  nan,  nan,  nan]]]], dtype=float32)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "workspace.FetchBlob('conv1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "workspace.FetchBlob('policy').shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "30px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_position": {
    "height": "856px",
    "left": "0px",
    "right": "20px",
    "top": "107px",
    "width": "179px"
   },
   "toc_section_display": "block",
   "toc_window_display": true,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
