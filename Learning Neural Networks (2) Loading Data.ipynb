{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Data\n",
    "In this notebook, we will load various data from local and external"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:This caffe2 python run does not have GPU support. Will run in CPU only mode.\n",
      "WARNING:root:Debug message: No module named caffe2_pybind11_state_gpu\n"
     ]
    }
   ],
   "source": [
    "# We'll also import a few standard python libraries\n",
    "from matplotlib import pyplot\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "# These are the droids you are looking for.\n",
    "from caffe2.python import core, workspace\n",
    "from caffe2.proto import caffe2_pb2\n",
    "\n",
    "# Let's show all plots inline.\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Fixed Width file\n",
    "In this chapter, we will load a fixed width file in local path. The file contains weather station geographic information, we will extract (longitude, latitude, elevate) and plot them on panel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "masked_array(data = [(10350.0, 46817.0, 14200.0) (--, --, --) (--, --, --) ...,\n",
       " (-96565.0, 40848.0, 3624.0) (-96854.0, 40695.0, 4182.0) (--, --, --)],\n",
       "             mask = [(False, False, False) ( True,  True,  True) ( True,  True,  True) ...,\n",
       " (False, False, False) (False, False, False) ( True,  True,  True)],\n",
       "       fill_value = (  1.00000000e+20,   1.00000000e+20,   1.00000000e+20),\n",
       "            dtype = [('longitude', '<f8'), ('latitude', '<f8'), ('elevate', '<f8')])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from StringIO import StringIO\n",
    "\n",
    "data_folder = os.path.join(os.path.expanduser('~'), 'python', 'tutorial_files','weather')\n",
    "#print(\"{}\".format(data_folder))\n",
    "\n",
    "raw_data = open(os.path.join(data_folder,'Station.txt'), 'r').read()\n",
    "#print('Raw data looks like this:')\n",
    "#print(raw_data[966:1300] + '...')\n",
    "\n",
    "np.genfromtxt(\\\n",
    "    StringIO(raw_data),\\\n",
    "    delimiter=(7,6,30,3,3,3,6,7,8,10,9,9),# width of each field \\\n",
    "    skip_header=22, # skip 22 lines of header \\\n",
    "    usecols=(8, 7, 9), # reorder colums from (latitude, longitude, elevate) to (longitude, latitude, elevate) \\\n",
    "    missing_values=\"-99999,-999999\", # missing_values will be replaced by numpy.nan \\\n",
    "    dtype=[('longitude','f8'),('latitude','f8'),('elevate','f8')], # \\\n",
    "    usemask=True) # required by using missing_values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Delimitered CSV file\n",
    "In this chapter we will load a comma-delimitered csv file in local path. The file contains POS transactions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([('2017/05/10 18:00:01',   5.50000000e+02),\n",
       "       ('2017/05/10 18:00:01',   3.10000000e+04),\n",
       "       ('2017/05/10 18:00:01',   1.00000000e-02), ...,\n",
       "       ('2017/05/10 17:30:00',   1.00000000e+04),\n",
       "       ('2017/05/10 17:30:00',   0.00000000e+00),\n",
       "       ('2017/05/10 17:30:00',   1.24800000e+03)],\n",
       "      dtype=[('trans_time', 'S19'), ('trans_amount', '<f8')])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from StringIO import StringIO\n",
    "\n",
    "data_folder = os.path.join(os.path.expanduser('~'), 'python', 'tutorial_files','transaction')\n",
    "#print(\"{}\".format(data_folder))\n",
    "\n",
    "raw_data = open(os.path.join(data_folder,'Excel-20170511104221.csv'), 'r').read()\n",
    "#print('Raw data looks like this:')\n",
    "#print(raw_data[:1138] + '...')\n",
    "\n",
    "np.genfromtxt(\\\n",
    "    StringIO(raw_data),\\\n",
    "    delimiter=\",\", # delimetered by comma \\\n",
    "    skip_header=1, # line 1 contains the header \\\n",
    "    usecols=(5, 6), # extract (trans_time, trans_amount) \\\n",
    "    autostrip=True, # remove TAB characters from data \\\n",
    "    dtype=[('trans_time','S19'),('trans_amount','f8')]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Delimitered CSV file (eyesight)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([('Young', 'Myope', 'No', 'Reduced', 'No lenses'),\n",
       "       ('Young', 'Myope', 'No', 'Normal', 'Soft lenses'),\n",
       "       ('Young', 'Myope', 'Yes', 'Reduced', 'No lenses'),\n",
       "       ('Young', 'Myope', 'Yes', 'Normal', 'Hard lenses'),\n",
       "       ('Young', 'Hypermetrope', 'No', 'Reduced', 'No lenses'),\n",
       "       ('Young', 'Hypermetrope', 'No', 'Normal', 'Soft lenses'),\n",
       "       ('Young', 'Hypermetrope', 'Yes', 'Reduced', 'No lenses'),\n",
       "       ('Young', 'Hypermetrope', 'Yes', 'Normal', 'Hard lenses'),\n",
       "       ('Pre-presbyopic', 'Myope', 'No', 'Reduced', 'No lenses'),\n",
       "       ('Pre-presbyopic', 'Myope', 'No', 'Normal', 'Soft lenses'),\n",
       "       ('Pre-presbyopic', 'Myope', 'Yes', 'Reduced', 'No lenses'),\n",
       "       ('Pre-presbyopic', 'Myope', 'Yes', 'Normal', 'Hard lenses'),\n",
       "       ('Pre-presbyopic', 'Hypermetrope', 'No', 'Reduced', 'No lenses'),\n",
       "       ('Pre-presbyopic', 'Hypermetrope', 'No', 'Normal', 'Soft lenses'),\n",
       "       ('Pre-presbyopic', 'Hypermetrope', 'Yes', 'Reduced', 'No lenses'),\n",
       "       ('Pre-presbyopic', 'Hypermetrope', 'Yes', 'Normal', 'Hard lenses'),\n",
       "       ('Presbyopic', 'Myope', 'No', 'Reduced', 'No lenses'),\n",
       "       ('Presbyopic', 'Myope', 'No', 'Normal', 'Soft lenses'),\n",
       "       ('Presbyopic', 'Myope', 'Yes', 'Reduced', 'No lenses'),\n",
       "       ('Presbyopic', 'Myope', 'Yes', 'Normal', 'Hard lenses'),\n",
       "       ('Presbyopic', 'Hypermetrope', 'No', 'Reduced', 'No lenses'),\n",
       "       ('Presbyopic', 'Hypermetrope', 'No', 'Normal', 'Soft lenses'),\n",
       "       ('Presbyopic', 'Hypermetrope', 'Yes', 'Reduced', 'No lenses'),\n",
       "       ('Presbyopic', 'Hypermetrope', 'Yes', 'Normal', 'Hard lenses')],\n",
       "      dtype=[('Age', 'S15'), ('Prescription', 'S13'), ('Astigmatic', 'S4'), ('Tear_production_rate', 'S8'), ('Class', 'S12')])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from StringIO import StringIO\n",
    "\n",
    "data_folder = os.path.join(os.path.expanduser('~'), 'python', 'tutorial_files','eyesight')\n",
    "#print(\"{}\".format(data_folder))\n",
    "\n",
    "raw_data = open(os.path.join(data_folder,'eyesight.csv'), 'r').read()\n",
    "#print('Raw data looks like this:')\n",
    "#print(raw_data[:1138] + '...')\n",
    "\n",
    "np.genfromtxt(\\\n",
    "    StringIO(raw_data),\\\n",
    "    delimiter=\",\", # delimetered by comma \\\n",
    "    skip_header=1, # line 1 contains the header \\\n",
    "    dtype=[('Age','S15'),('Prescription','S13'),('Astigmatic','S4'),('Tear production rate','S8'),('Class','S12')]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data from Internet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<!DOCTYPE HTML>\n",
      "<html>\n",
      "\n",
      "<head>\n",
      "    <meta charset=\"utf-8\">\n",
      "\n",
      "    <title>Jupyter Notebook</title>\n",
      "    <link rel=\"shortcut icon\" type=\"image/x-icon\" href=\"/static/base/images/favicon.ico?v=97c6417ed01bdc0...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/requests/packages/urllib3/connectionpool.py:852: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning)\n",
      "/usr/local/lib/python2.7/dist-packages/requests/packages/urllib3/connectionpool.py:852: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning)\n"
     ]
    }
   ],
   "source": [
    "import requests, requests.auth\n",
    "remoteurl = 'https://use.davin.wang:8443/tree' #URL for testing\n",
    "headers = {\n",
    "    'User-Agent':'Mozilla/4.0 (compatible; MSIE 5.5; Windows NT)',\n",
    "}\n",
    "data = {\n",
    "    'param1':'value1'\n",
    "}\n",
    "auth = requests.auth.HTTPBasicAuth('user','pass')\n",
    "r = requests.get(remoteurl, data=data, headers=headers, auth=auth, verify=False)\n",
    "\n",
    "if r.status_code == 200 :\n",
    "    #打印结果\n",
    "    print(r.content[:200]+'...')\n",
    "    #打印爬取网页的各类信息"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Invoke RESTFul API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<!DOCTYPE HTML>\n",
      "<html>\n",
      "\n",
      "<head>\n",
      "    <meta charset=\"utf-8\">\n",
      "\n",
      "    <title>Jupyter Notebook</title>\n",
      "    <link rel=\"shortcut icon\" type=\"image/x-icon\" href=\"/static/base/images/favicon.ico?v=97c6417ed01bdc0...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/requests/packages/urllib3/connectionpool.py:852: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning)\n",
      "/usr/local/lib/python2.7/dist-packages/requests/packages/urllib3/connectionpool.py:852: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning)\n"
     ]
    }
   ],
   "source": [
    "import requests, requests.auth, json\n",
    "remoteurl = 'https://use.davin.wang:8443/tree' #URL for testing\n",
    "headers = {\n",
    "    'Content-Type':'application/json'\n",
    "}\n",
    "payload = {\n",
    "    'param1':'value1'\n",
    "}\n",
    "auth = requests.auth.HTTPBasicAuth('user','pass')\n",
    "r = requests.get(remoteurl, data=json.dumps(payload), headers=headers, auth=auth, verify=False)\n",
    "\n",
    "if r.status_code == 200 :\n",
    "    #打印结果\n",
    "    print(r.content[:200]+'...')\n",
    "    #打印爬取网页的各类信息"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Create DataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First let's import a few things needed.\n",
    "%matplotlib inline\n",
    "import urllib2 # for downloading the dataset from the web.\n",
    "import numpy as np\n",
    "from matplotlib import pyplot\n",
    "from StringIO import StringIO\n",
    "from caffe2.python import core, utils, workspace\n",
    "from caffe2.proto import caffe2_pb2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data\n",
    "Load data and separate `features` and `labels`. `features` contains array of `[longitude, latitude]` and `labels` contains array of `elevate`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os, datetime\n",
    "from StringIO import StringIO\n",
    "\n",
    "data_folder = os.path.join(os.path.expanduser('~'), 'python', 'tutorial_files','weather')\n",
    "#print(\"{}\".format(data_folder))\n",
    "\n",
    "raw_data = open(os.path.join(data_folder,'Station.txt'), 'r').read()\n",
    "#print('Raw data looks like this:')\n",
    "#print(raw_data[966:1300] + '...')\n",
    "\n",
    "stations = np.genfromtxt(\\\n",
    "    StringIO(raw_data),\\\n",
    "    delimiter=(7,6,30,3,3,3,6,7,8,10,9,9),# width of each field \\\n",
    "    skip_header=22, # skip 22 lines of header \\\n",
    "    usecols=(8, 7, 9), # reorder colums from (latitude, longitude, elevate) to (longitude, latitude, elevate) \\\n",
    "    missing_values=\"-99999,-999999\", # missing_values will be replaced by numpy.nan \\\n",
    "    dtype=[('longitude','f8'),('latitude','f8'),('elevate','f8')], # \\\n",
    "    usemask=True) # required by using missing_values\n",
    "\n",
    "data_set = [ stations[i] for i in range(len(stations)) if stations[i][0] and stations[i][1] and stations[i][2]]\n",
    "\n",
    "features = np.array([ [t[0]/1000/180, t[1]/1000/90] for t in data_set ], dtype=np.float32)\n",
    "labels = np.array([ t[2]/10/10000 for t in data_set ], dtype=np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Train Set and Test Set\n",
    "Firstly, we randomize the data set. Then split the data set into train set and test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "random_index = np.random.permutation(len(data_set))\n",
    "features = features[random_index]\n",
    "labels = labels[random_index]\n",
    "\n",
    "train_features = features[0:20000]\n",
    "train_labels = labels[0:20000]\n",
    "test_features = features[20000:21000]\n",
    "test_labels = labels[20000:21000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert to DB form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is what the tensor proto looks like for a feature and its label:\n",
      "protos {\n",
      "  dims: 2\n",
      "  data_type: FLOAT\n",
      "  float_data: 0.650650024414\n",
      "  float_data: 0.322033345699\n",
      "}\n",
      "protos {\n",
      "  data_type: FLOAT\n",
      "  float_data: 0.00490000005811\n",
      "}\n",
      "\n",
      "This is the compact string that gets written into the db:\n",
      "\n",
      "\u000e\b\u0002\u0010\u0001\u001a\b\u0000�&?��>\n",
      "\b\u0010\u0001\u001a\u0004.��;\n"
     ]
    }
   ],
   "source": [
    "# First, let's see how one can construct a TensorProtos protocol buffer from numpy arrays.\n",
    "feature_and_label = caffe2_pb2.TensorProtos()\n",
    "feature_and_label.protos.extend([\n",
    "    utils.NumpyArrayToCaffe2Tensor(features[0]),\n",
    "    utils.NumpyArrayToCaffe2Tensor(labels[0])])\n",
    "print('This is what the tensor proto looks like for a feature and its label:')\n",
    "print(str(feature_and_label))\n",
    "print('This is the compact string that gets written into the db:')\n",
    "print(feature_and_label.SerializeToString())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write Back"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, actually write the db.\n",
    "\n",
    "def write_db(db_type, db_name, features, labels):\n",
    "    db = core.C.create_db(db_type, db_name, core.C.Mode.write)\n",
    "    transaction = db.new_transaction()\n",
    "    for i in range(features.shape[0]):\n",
    "        feature_and_label = caffe2_pb2.TensorProtos()\n",
    "        feature_and_label.protos.extend([\n",
    "            utils.NumpyArrayToCaffe2Tensor(features[i]),\n",
    "            utils.NumpyArrayToCaffe2Tensor(labels[i])])\n",
    "        transaction.put(\n",
    "            'train_{:0=5}'.format(i),\n",
    "            feature_and_label.SerializeToString())\n",
    "    # Close the transaction, and then close the db.\n",
    "    del transaction\n",
    "    del db\n",
    "\n",
    "current_folder = os.path.join(os.path.expanduser('~'), 'python')\n",
    "data_folder = os.path.join(current_folder, 'tutorial_data', 'weather_station')\n",
    "    \n",
    "write_db(\"minidb\", os.path.join(data_folder, 'weather-station-train-minidb'), train_features, train_labels)\n",
    "write_db(\"minidb\", os.path.join(data_folder, 'weather-station-test-minidb'), test_features, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read from DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(BlobReference(\"X\"), BlobReference(\"Y\"))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net_proto = core.Net(\"example_reader\")\n",
    "dbreader = net_proto.CreateDB([], \"dbreader\", db=os.path.join(data_folder, 'weather-station-train-minidb'), db_type=\"minidb\")\n",
    "net_proto.TensorProtosDBInput([dbreader], [\"X\", \"Y\"], batch_size=100)\n",
    "\n",
    "#print(\"The net looks like this:\")\n",
    "#print(str(net_proto.Proto()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "workspace.CreateNet(net_proto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The first batch of feature is:\n",
      "[ 0.31248334  0.28462222]\n",
      "The first batch of label is:\n",
      "0.001\n"
     ]
    }
   ],
   "source": [
    "# Let's run it to get batches of features.\n",
    "workspace.RunNet(net_proto.Proto().name)\n",
    "print(\"The first batch of feature is:\")\n",
    "print(workspace.FetchBlob(\"X\")[0])\n",
    "print(\"The first batch of label is:\")\n",
    "print(workspace.FetchBlob(\"Y\")[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "105px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_position": {
    "height": "576px",
    "left": "0px",
    "right": "auto",
    "top": "107px",
    "width": "212px"
   },
   "toc_section_display": "block",
   "toc_window_display": true,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
