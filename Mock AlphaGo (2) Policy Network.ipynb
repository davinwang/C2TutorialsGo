{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mock AlphaGo (2) - Policy Network\n",
    "In this notebook, we will build the model of AlphaGo's Policy Network, which is a dCNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running in GPU mode on default device 0\n",
      "Training model from 0 to 50000 iterations\n"
     ]
    }
   ],
   "source": [
    "import os, numpy as np\n",
    "from caffe2.python import core, model_helper, workspace, brew, utils\n",
    "from caffe2.proto import caffe2_pb2\n",
    "\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot\n",
    "\n",
    "CONV_LEVEL = 13 # [3,13(alphago)] How many CNN will be used in the model\n",
    "FILTERS = 192 # 128/192(alphago)/256/384 How many K will be used in the model\n",
    "BASE_LR = -0.003 # (-0.01,0) The base Learning Rate, alphago uses -0.003 and half the number every 80m steps\n",
    "\n",
    "if workspace.has_gpu_support:\n",
    "    device_opts = core.DeviceOption(caffe2_pb2.CUDA, workspace.GetDefaultGPUID())\n",
    "    print('Running in GPU mode on default device {}'.format(workspace.GetDefaultGPUID()))\n",
    "else :\n",
    "    device_opts = core.DeviceOption(caffe2_pb2.CPU, 0)\n",
    "    print('Running in CPU mode')\n",
    "\n",
    "TRAIN_BATCHES = 64 # how many samples will be trained within one mini-batch, depends on your hardware\n",
    "PRE_TRAINED_ITERS = 0 # [0, infinity) how many batches the model has been trained before\n",
    "SKIP_TRAINED_DATA = 0 # [0, infinity) if this is a resumed training, how many input data will be skipped\n",
    "TRAIN_ITERS = 50000 #500000 # [0, infinity) how many batches the model will be trained\n",
    "TEST_BATCHES = 100 # how many samples will be tested within one mini-batch\n",
    "TEST_ITERS = 1000 # how many batches the model will be tested\n",
    "\n",
    "ROOT_FOLDER = os.path.join(os.path.expanduser('~'), 'python', 'tutorial_data','go','param') # folder stores the loss/accuracy log\n",
    "DATA_FOLDER = os.path.join(os.path.expanduser('~'), 'python', 'tutorial_data','go')\n",
    "TRAIN_DATA = os.path.join(DATA_FOLDER,'train_data') # db folder stores the preprocessed games\n",
    "TEST_DATA = os.path.join(DATA_FOLDER,'test_data') # db folder stores the preprocessed games\n",
    "\n",
    "# if this is a resumed training, where to load the init_param from\n",
    "LOAD_FOLDER = os.path.join(ROOT_FOLDER, \"conv={}-k={}-iter={}\".format(CONV_LEVEL,FILTERS,PRE_TRAINED_ITERS))\n",
    "\n",
    "# if the model will be saved for future resume training, where to store it\n",
    "SAVE_FOLDER = os.path.join(ROOT_FOLDER, \"conv={}-k={}-iter={}\".format(CONV_LEVEL,FILTERS,PRE_TRAINED_ITERS+TRAIN_ITERS))\n",
    "\n",
    "workspace.ResetWorkspace(ROOT_FOLDER)\n",
    "\n",
    "print('Training model from {} to {} iterations'.format(PRE_TRAINED_ITERS,PRE_TRAINED_ITERS+TRAIN_ITERS))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AlphaGo Neural Network Architecture\n",
    "Refer to AlphaGo\n",
    "> The input to the policy network is a 19 x 19 x 48 image stack consisting of 48 feature planes. The first hidden layer zero-pads the input into a 23 x 23 image, then convolves k filters of kernel size 5 x 5 with stride 1 with the input image and applies a rectifier nonlinearity. Each of the subsequent hidden layers 2 to 12 zero pads the respective previous hidden layer into a 21 x 21 image, then convolves k filters of kernel size 3x3 with stride 1, again followed by a rectifier nonlinearity. The final layer convolves 1 filter of kernel size 1 x 1 with stride 1, with a different bias for each position, and applies a softmax function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Input\n",
    "This program requires input data in shape of 48 x 19 x 19, which is preprocessed from SGF files, and label of scalar, which represents the next move.\n",
    "    The board of Go is symmetric in 8 directions, so this method can be enhanced to transpose and mirror the input data in 8 directions. According to DeepMind, training the model with symmetric data in 8 directions will increase the accuracy data by around 1-2% which is significant. However, it also takes 8 times longer to train the model. Spending same amount of time in Reinforced Training instead of symmetric data may achieve better winning rate. AlphaGo didn't use the symmetric data for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from modeling import AddInput"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from modeling import AddConvModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy\n",
    "Please note predict is 4 dimensional tensor in shape of N x 1 x 19 x 19, and label is 2 dimensional tensor in shape of N x 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from modeling import AddAccuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Operator (Backward Propagation)\n",
    "The training operator is almost same as MNIST. Refer to AlphaGo\n",
    ">The step-size \u000b",
    " was initialized to 0.003 and was halved every 80\n",
    "million training steps, without momentum terms, and a mini-batch size of m = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from modeling import AddTrainingOperators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the actual network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "arg_scope = {\"order\": \"NCHW\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:You are creating an op that the ModelHelper does not recognize: OneHot.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Skip model only has DBInput to waste the input\n",
    "skip_model = model_helper.ModelHelper(name=\"skip_model\", arg_scope=arg_scope, init_params=True)\n",
    "_d, _l, _o = AddInput(\n",
    "    skip_model, batch_size=TRAIN_BATCHES,\n",
    "    db=TRAIN_DATA,\n",
    "    db_type='leveldb')\n",
    "# Initialize params and create network\n",
    "workspace.RunNetOnce(skip_model.param_init_net)\n",
    "workspace.CreateNet(skip_model.net, overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:You are creating an op that the ModelHelper does not recognize: OneHot.\n",
      "WARNING:root:You are creating an op that the ModelHelper does not recognize: PadImage.\n",
      "WARNING:root:You are creating an op that the ModelHelper does not recognize: PadImage.\n",
      "WARNING:root:You are creating an op that the ModelHelper does not recognize: PadImage.\n",
      "WARNING:root:You are creating an op that the ModelHelper does not recognize: PadImage.\n",
      "WARNING:root:You are creating an op that the ModelHelper does not recognize: PadImage.\n",
      "WARNING:root:You are creating an op that the ModelHelper does not recognize: PadImage.\n",
      "WARNING:root:You are creating an op that the ModelHelper does not recognize: PadImage.\n",
      "WARNING:root:You are creating an op that the ModelHelper does not recognize: PadImage.\n",
      "WARNING:root:You are creating an op that the ModelHelper does not recognize: PadImage.\n",
      "WARNING:root:You are creating an op that the ModelHelper does not recognize: PadImage.\n",
      "WARNING:root:You are creating an op that the ModelHelper does not recognize: PadImage.\n",
      "WARNING:root:You are creating an op that the ModelHelper does not recognize: PadImage.\n",
      "WARNING:root:You are creating an op that the ModelHelper does not recognize: SigmoidCrossEntropyWithLogits.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train Net: DBInput ==> Predict Net ==> Loss ==> Backward Propergation\n",
    "with core.DeviceScope(device_opts):\n",
    "    train_model = model_helper.ModelHelper(name=\"policy_train\", arg_scope=arg_scope, init_params=True)\n",
    "    data, label, onehot = AddInput(\n",
    "        train_model, batch_size=TRAIN_BATCHES,\n",
    "        db=TRAIN_DATA,\n",
    "        db_type='leveldb')\n",
    "    predict = AddConvModel(train_model, data, conv_level=CONV_LEVEL, filters=FILTERS)\n",
    "    AddAccuracy(train_model, predict, label)\n",
    "    AddTrainingOperators(train_model, predict, onehot, base_lr=BASE_LR)\n",
    "# Initialize params and create network\n",
    "workspace.RunNetOnce(train_model.param_init_net)\n",
    "workspace.CreateNet(train_model.net, overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:You are creating an op that the ModelHelper does not recognize: OneHot.\n",
      "WARNING:root:You are creating an op that the ModelHelper does not recognize: PadImage.\n",
      "WARNING:root:You are creating an op that the ModelHelper does not recognize: PadImage.\n",
      "WARNING:root:You are creating an op that the ModelHelper does not recognize: PadImage.\n",
      "WARNING:root:You are creating an op that the ModelHelper does not recognize: PadImage.\n",
      "WARNING:root:You are creating an op that the ModelHelper does not recognize: PadImage.\n",
      "WARNING:root:You are creating an op that the ModelHelper does not recognize: PadImage.\n",
      "WARNING:root:You are creating an op that the ModelHelper does not recognize: PadImage.\n",
      "WARNING:root:You are creating an op that the ModelHelper does not recognize: PadImage.\n",
      "WARNING:root:You are creating an op that the ModelHelper does not recognize: PadImage.\n",
      "WARNING:root:You are creating an op that the ModelHelper does not recognize: PadImage.\n",
      "WARNING:root:You are creating an op that the ModelHelper does not recognize: PadImage.\n",
      "WARNING:root:You are creating an op that the ModelHelper does not recognize: PadImage.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test Net: DBInput ==> Predict Net ==> Accuracy\n",
    "with core.DeviceScope(device_opts):\n",
    "    test_model = model_helper.ModelHelper(name=\"policy_test\", arg_scope=arg_scope, init_params=False)\n",
    "    data, label, onehot = AddInput(\n",
    "        test_model, batch_size=TEST_BATCHES,\n",
    "        db=TEST_DATA,\n",
    "        db_type='leveldb')\n",
    "    predict = AddConvModel(test_model, data, conv_level=CONV_LEVEL, filters=FILTERS)\n",
    "    AddAccuracy(test_model, predict, label)\n",
    "# Initialize params and create network\n",
    "workspace.RunNetOnce(test_model.param_init_net)\n",
    "workspace.CreateNet(test_model.net, overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deploy Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:You are creating an op that the ModelHelper does not recognize: PadImage.\n",
      "WARNING:root:You are creating an op that the ModelHelper does not recognize: PadImage.\n",
      "WARNING:root:You are creating an op that the ModelHelper does not recognize: PadImage.\n",
      "WARNING:root:You are creating an op that the ModelHelper does not recognize: PadImage.\n",
      "WARNING:root:You are creating an op that the ModelHelper does not recognize: PadImage.\n",
      "WARNING:root:You are creating an op that the ModelHelper does not recognize: PadImage.\n",
      "WARNING:root:You are creating an op that the ModelHelper does not recognize: PadImage.\n",
      "WARNING:root:You are creating an op that the ModelHelper does not recognize: PadImage.\n",
      "WARNING:root:You are creating an op that the ModelHelper does not recognize: PadImage.\n",
      "WARNING:root:You are creating an op that the ModelHelper does not recognize: PadImage.\n",
      "WARNING:root:You are creating an op that the ModelHelper does not recognize: PadImage.\n",
      "WARNING:root:You are creating an op that the ModelHelper does not recognize: PadImage.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train Net: Blob('data') ==> Predict Net ==> Blob('predict')\n",
    "with core.DeviceScope(device_opts):\n",
    "    deploy_model = model_helper.ModelHelper(name=\"policy_deploy\", arg_scope=arg_scope, init_params=False)\n",
    "    AddConvModel(deploy_model, \"data\", conv_level=CONV_LEVEL, filters=FILTERS)\n",
    "# Initialize params and create network\n",
    "workspace.RunNetOnce(deploy_model.param_init_net)\n",
    "workspace.CreateNet(deploy_model.net, overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the training and testing\n",
    "### resume from last training\n",
    "    Training a multi-level CNN takes quite a long time. To pause-and-resume the training, set the PRE_TRAINED_ITERS so the program will start from where last time it was."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import caffe2.python.predictor.predictor_exporter as pe\n",
    "\n",
    "# construct the model to be exported\n",
    "pe_meta = pe.PredictorExportMeta(\n",
    "    predict_net=deploy_model.net.Proto(),\n",
    "    parameters=[str(b) for b in deploy_model.params], \n",
    "    inputs=[\"data\"],\n",
    "    outputs=[\"predict\"],\n",
    ")\n",
    "\n",
    "if PRE_TRAINED_ITERS > 0:\n",
    "    #load_net(LOAD_INIT_NET, LOAD_PREDICT_NET)\n",
    "    # load the predict net\n",
    "    with core.DeviceScope(device_opts):\n",
    "        deploy_model.net = pe.prepare_prediction_net(os.path.join(LOAD_FOLDER, \"policy_model.minidb\"), \"minidb\")#, device_option=device_opts)\n",
    "    print('Params loaded from {}'.format(LOAD_FOLDER))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#%%capture output # Jupyter magic command to capture the output\n",
    "\n",
    "if TRAIN_ITERS > 0:\n",
    "    # skip the data which should not be trained again\n",
    "    for i in range(SKIP_TRAINED_DATA):\n",
    "        workspace.RunNet(skip_model.net)\n",
    "    \n",
    "    # set the number of iterations and track the accuracy & loss\n",
    "    accuracy = np.zeros(TRAIN_ITERS)\n",
    "    loss = np.zeros(TRAIN_ITERS)\n",
    "    # Now, run the network \n",
    "    for i in range(TRAIN_ITERS):\n",
    "        workspace.RunNet(train_model.net)\n",
    "        accuracy[i] = workspace.FetchBlob('accuracy')\n",
    "        loss[i] = workspace.FetchBlob('loss')\n",
    "        # checkpoint every 10000 iterations\n",
    "        if i > 0 and i % 10000 == 0:\n",
    "            if not os.path.exists(SAVE_FOLDER):\n",
    "                os.makedirs(SAVE_FOLDER)\n",
    "            pe.save_to_db(\"minidb\", os.path.join(SAVE_FOLDER, \"policy_model_checkpoint_{}.minidb\".format(PRE_TRAINED_ITERS+i)), pe_meta)\n",
    "            print('Checkpoint {} saved to {}'.format(PRE_TRAINED_ITERS+i,SAVE_FOLDER))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if TRAIN_ITERS > 0:\n",
    "    # After the execution is done, plot the values.\n",
    "    pyplot.plot(loss, 'b')\n",
    "    pyplot.plot(accuracy, 'r')\n",
    "    pyplot.legend(('Loss', 'Accuracy'), loc='upper right')\n",
    "    print('Training Accuracy: %f' % accuracy.mean())\n",
    "    print('Loss: %f' % loss.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_accuracy = np.zeros(TEST_ITERS)\n",
    "for i in range(TEST_ITERS):\n",
    "    workspace.RunNet(test_model.net)\n",
    "    test_accuracy[i] = workspace.FetchBlob('accuracy')\n",
    "# After the execution is done, let's plot the values.\n",
    "pyplot.plot(test_accuracy, 'r')\n",
    "pyplot.title('Acuracy over test batches.')\n",
    "print('test_accuracy: %f' % test_accuracy.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the work for future use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if TRAIN_ITERS > 0:\n",
    "    if not os.path.exists(SAVE_FOLDER):\n",
    "        os.makedirs(SAVE_FOLDER)\n",
    "    # save the model to a file. Use minidb as the file format\n",
    "#    pe.save_to_db(\"minidb\", os.path.join(SAVE_FOLDER, \"policy_model.minidb\"), pe_meta)\n",
    "    print('Params saved to {}'.format(SAVE_FOLDER))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "30px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_position": {
    "height": "856px",
    "left": "0px",
    "right": "20px",
    "top": "107px",
    "width": "179px"
   },
   "toc_section_display": "block",
   "toc_window_display": true,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
